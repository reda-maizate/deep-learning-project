{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6737c3f4",
   "metadata": {},
   "source": [
    "**ConvNets**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6ec4b4",
   "metadata": {},
   "source": [
    "Le principe d'utilisation d'un ConvNets reste les données a multiples dimensions.\n",
    "Dans notre cas les données sont des images c-à-d des données à deux dimensions \n",
    "Le convnets est le réseau qui s'adapte le mieux aux images puisque celui-ci s'inspire du cortex visuel\n",
    "Comme tout réseau la topologie est importante \n",
    "On a pas chercher ici à prendre le meilleur réseau puisque l'idée d'un réseau est de l'optimiser et le but est de comprendre comment les hyperparamètres peuvent changer un réseau et ses résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8580acd1",
   "metadata": {},
   "source": [
    "Ici on à crée un réseau initiale et ce réseau va nous servir de base dans notre étude et en voici les paramètres : \n",
    "Les paramètres et le réseau choisis sont empirique et constitue une base d'étude \n",
    "    \n",
    "NUM_LAYERS = list(range(3, 6))\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 300\n",
    "SHUFFLE = True\n",
    "learning_rates = 0.001\n",
    "momentums = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf68917b",
   "metadata": {},
   "source": [
    "# Ajouter image réseau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae10eada",
   "metadata": {},
   "source": [
    "### Caractéristique de comparaison \n",
    "\n",
    "- Surapptentissage ou non\n",
    "- Allure de la courbe\n",
    "- Vitesse d'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4de1be",
   "metadata": {},
   "source": [
    "## Max pooling vs Average pooling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "316c75cc",
   "metadata": {},
   "source": [
    "Nous allons comparer deux type de couche utilisés dans les convnet : le max pooling et l'average pooling\n",
    "la courbes du dessus est celle du max pooling et celle d'en dessous est celle de l'avg pooling\n",
    "\n",
    "Lorsque l'on regarde l'aprentissage des deux réseaux on remarque que les deux courbes sont similaires dans leur stabilité et ne présente aucune tendance au surapprentissage.\n",
    "Néanmoins on peut remarque la différence qui s'opère lorsque que l'apprentissage arrive dans la phase de plateau avec respectivement avec 0.45 et 0.35 pour le max et l'avg.\n",
    "Pour un même réseau l'utilisation des deux couches présentent un différence sur la vitesse et la qualité(en terme d'accuracy) de l'apprentissage. \n",
    "> Comment peut on expliquer cette différence : que se passe t-il dans les couches ?\n",
    "Max pooling prend la valeur maximum de la portion d'image couverte par le kernel et Avg pooling sa valeur moyenne. La différence se tient ici. Etant donne que les valeurs prisent ne sont pas les mêmes alors la capacité à capturer l'information va changer aussi. Les caractéristiques des deux layers vont drastiquement influer sur les résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b1b4b1",
   "metadata": {},
   "source": [
    "## Séquential vs Fonctionnal "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd07ffc",
   "metadata": {},
   "source": [
    "Nous allons comparer ici deux réseaux qui utilise les mêmes caractéristiques avec fonction d'activation optimizer learning rate et momentum identique, seul la topologie va changer. Nous avons un réseau séquentiel et un réseau fonctionnel. \n",
    "\n",
    "Lorsque l'on regarde l'aprentissage des deux réseaux on remarque que les deux courbes sont similaires dans leur stabilité et ne présente aucune tendance au surapprentissage. Néanmoins on peut remarque la différence qui s'opère lorsque que l'apprentissage arrive dans la phase de plateau avec respectivement avec 0.45 et 0.35 pour le max et l'avg. Pour un même réseau l'utilisation des deux couches présentent un différence sur la vitesse et la qualité(en terme d'accuracy) de l'apprentissage.  \n",
    "\n",
    "La différence notable que l'on peut observer est dans le plateau. En effet le réseau séquentiel présente de meilleur résultat mais un écart se forme entre les deux courbes se qui peut potentiellement montrer un éventuelle surapprentissage à avenir. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7112dcc0",
   "metadata": {},
   "source": [
    "## Padding = same vs Padding = valid "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e529d5",
   "metadata": {},
   "source": [
    "Nous allons comparer deux versions d'un même paramètre qu'est le padding avec le padding en \"same\" ou en \"valid\". \n",
    "Lorsque l'on regarde l'apprentissage des deux réseaux on remarque que les deux courbes sont similaires dans leur stabilité même si la courbe rouge (padding \"valid\") présente quelques pics en dent de scie au cours de l'appretissage et ne présente aucune tendance au surapprentissage.\n",
    "Néanmoins on peut remarque la différence qui s'opère lorsque que l'apprentissage arrive dans la phase de plateau avec cette fois ci un écart très faible entre les deux. Ici la différence d'accuracy et de loss est très faible\n",
    "> Comment peut on expliquer cette différence : que se passe t-il avec le padding ? Le principe du padding est dans notre cas de compenser le manque d'information présent sur les bords d'une image lorsque le kernel passe. Dans le cas ou le padding est en \"valid\" l'image est conserver telle qu'initialement donné au model. Cela implique que si le kernel arrive en bord d'image, il est possible d'avoir une perte d'information du à la dimension du kernel et de l'image. Dans l'autre donc \"same\", des valeurs vont être ajouter de part et d'autre de l'image pour conserver les bords et donc conserver de l'information. Cela peut se remarquer car pour deux réseaux similaires, en début de courbe on peut voir que l'accuracy ne croit pas autant entres les deux versions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8adbca6",
   "metadata": {},
   "source": [
    "## Fonction d'activation tanh relu sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5240436",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2a1a908",
   "metadata": {},
   "source": [
    "## Optimizer SGD ADAM RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe493e1",
   "metadata": {},
   "source": [
    "Nous allons comparer 3 optimizer que son SGD ADAM et RMSprop. \n",
    "Premièrement on peut remarquer que sur les courbes d'apprentissages trois profils sont présents: \n",
    "- Le premier est celui du SGD, la courbe à une progression lente l'accuracy  ne démarrant qu'à partir de 0.10 mais lisse sans dents de scie et le plateau se forme vers 0.45. La courbe ne montre aucun signe de surapprentrissage\n",
    "- Le deuxième est celui du RMSprop et d'Adam, avec une courbe à progression plus rapide avec une accuracy démarrant au alentour de 0.40 et formant un plateau vers 0.8. Les deux courbes montrent des signes de surapprentissage. \n",
    "\n",
    "Ces deux profils correspond aux valeures d'accuracy des optimizers. Maintenant regardons la loss : \n",
    "Cette fois ci chaque optimizer décrit un profil différent : \n",
    "- SGD montre un courbe lise avec une décroissance progressive \n",
    "- RMSprop montre une courbe de train et de validation complétement différente avec ue augmentation progressive et en dent de scie pour la validation et une courbe de train plus stable  \n",
    "- Adam les courbes sont plus lisses mais tout comme RMSprop la courbe de loss de validation a tendance à croitre et un écart se creuse avec la courbe de train. \n",
    "\n",
    "\n",
    "Ce que peut en déduire c'est que Adam et RMSprop accélère l'apprentissage au détriment d'un surapprentissage comme contrecoup \n",
    "SGD révèle une courbe d'apprentissage plus longue à se mettre en place mais plus stable dans les résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f15043",
   "metadata": {},
   "source": [
    "## Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c818fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c972c80",
   "metadata": {},
   "source": [
    "## Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45df94b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
