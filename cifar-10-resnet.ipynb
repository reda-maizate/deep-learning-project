{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c14d082c-b9bd-4d36-9039-92005273c9c8",
   "metadata": {},
   "source": [
    "# CIFAR-10 Linear Model\n",
    "\n",
    "La première étape intermédiaire de notre projet est d'utiliser les algorithmes ci-dessous sur le célébre dataset CIFAR-10.\n",
    "\n",
    "Les algorithmes à étudier :\n",
    "\n",
    "**Modèles précédents**\n",
    "- Modèle Linéaire\n",
    "- Perceptron Multicouches\n",
    "\n",
    "**Nouveaux modèles**\n",
    "- ConvNet(s)\n",
    "- ResNets / HighwayNets \n",
    "- RNN(s)\n",
    "\n",
    "Pour chacun des algorithmes cités, il faut :\n",
    "1. L'influence de tous les hyperparamètres des modèles\n",
    "    - Structure\n",
    "    - Fonctions d'activations\n",
    "    - etc.\n",
    "2. Les paramètres des algorithmes d'apprentissages\n",
    "    - Learning Rate\n",
    "    - Momentum\n",
    "    - etc.\n",
    "    \n",
    "----\n",
    "\n",
    "### Méthodologie\n",
    "1. Créer un modèle classique.\n",
    "2. Entraîner le modèle pendant 500 epochs.\n",
    "3. Examiner sa courbe TensorBoard et son accuracy.\n",
    "4. Augmenter un des hyperparamètre.\n",
    "5. Réduire ce même hyperparamètre.\n",
    "6. Dire l'influence de cette hyperparamètre sur la courbe et sur le modèle de manière générale.\n",
    "7. Recommencer à partir de l'étape 3 pour tout les hyperparamètres possibles.\n",
    "\n",
    "#### Hyperparamètres\n",
    "- Batch size\n",
    "- Learning rate\n",
    "- Momentum\n",
    "- Structure\n",
    "- Fonction d'activation\n",
    "- Initialization de kernel\n",
    "- Regularizers (Dropout, L1 Norm, L2 Norm)\n",
    "\n",
    "#### Qui s'occupe de quoi ?\n",
    "- Perceptron (Mamadian)\n",
    "- MLP (Réda M.)\n",
    "- ConvNet (Reda B.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e378f01b-f353-4e9b-8a80-73c9b83f6bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, BatchNormalization, Input, Average, MaxPool2D\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from tensorflow.keras.optimizers import SGD,Adam,RMSprop\n",
    "from tensorflow.keras.activations import relu, softmax, tanh, sigmoid\n",
    "from tensorflow.keras.initializers import he_normal, glorot_uniform\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.models import Model, load_model , Sequential\n",
    "from tensorflow.keras.regularizers import l2, l1, l1_l2\n",
    "from tensorflow.random import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5f4e0a-0bbb-4378-a289-d8646e065ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Version de TensorFlow :\", tf.__version__)\n",
    "print(\"Nom du GPU :\", tf.test.gpu_device_name())\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tf.config.optimizer.set_jit(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9a71ea-ca82-439e-8f2e-8ecef5e0e192",
   "metadata": {},
   "source": [
    "## Importation du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefc0c44-22d0-497f-affc-949cde51e72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd58edc-df9b-49ed-ab39-9572fa1ed97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "IMG_SIZE = x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ff4114-34f9-4e83-9ee2-a934a53403c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 256\n",
    "x_test = x_test.astype('float32') / 256\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "y_test = to_categorical(y_test, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850b786e-e2ab-40b1-b5cc-b5cdf5125b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = os.path.join(\"logs\") \n",
    "MODEL_DIR = os.path.join(\"models\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc27c2c",
   "metadata": {},
   "source": [
    "## Fixer les seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff124095",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42) # TensorFlow\n",
    "seed(42) # NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f699da7-beb8-4e31-b040-cd63a01ab54a",
   "metadata": {},
   "source": [
    "# Modèle ResNets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0b9d56",
   "metadata": {},
   "source": [
    "##### Learning rate et momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a648421",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LAYERS = list(range(3, 6))\n",
    "OPTIMIZER = SGD\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 200\n",
    "SHUFFLE = True\n",
    "learning_rates = [0.5,0.1, 0.01, 0.001]\n",
    "momentums = [0.25, 0.5, 0.9]\n",
    "\n",
    "def ResNet(num_layer, filters_by_layers):\n",
    "    input_layer = Input(shape=(32, 32, 3))\n",
    "    hidden_layers = input_layer\n",
    "    \n",
    "    for n in range(num_layer):\n",
    "        prev_layer = hidden_layers\n",
    "        hidden_layers = Conv2D(filters_by_layers[n], (3, 3), padding='same', activation=relu,\n",
    "                                            kernel_initializer=he_normal)(hidden_layers)\n",
    "        #hidden_layers = Dropout(0.2)(hidden_layers)\n",
    "        if n > 0:\n",
    "            hidden_layers = Average()([hidden_layers, prev_layer])\n",
    "        else:\n",
    "            hidden_layers = Average()([hidden_layers, Dense(32)(prev_layer)])\n",
    "    \n",
    "    hidden_layers = Flatten()(hidden_layers)   \n",
    "    output_layer = Dense(NUM_CLASSES, activation=softmax)(hidden_layers)\n",
    "    return Model(input_layer, output_layer)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for mom in momentums:\n",
    "        num_layer = int(np.random.choice(NUM_LAYERS, 1))\n",
    "        filters_by_layers = [32 for x in range(1, num_layer+1)]\n",
    "\n",
    "        resnet = ResNet(num_layer, filters_by_layers)\n",
    "        resnet.compile(loss=categorical_crossentropy,\n",
    "                    optimizer=SGD(lr, momentum=mom),\n",
    "                    metrics=categorical_accuracy)\n",
    "        RESNET_LOG = os.path.join(LOG_DIR, \"resnet\",\n",
    "                        f\"resnet_ep_{EPOCHS}_bs_{BATCH_SIZE}_opt_SGD_lr_{lr}_mom_{mom}_layers_{'_'.join(str(e) for e in filters_by_layers)}_af_relu\")\n",
    "        RESNET_MODEL = os.path.join(MODEL_DIR, \"resnet\",\n",
    "                        f\"resnet_ep_{EPOCHS}_bs_{BATCH_SIZE}_opt_SGD_lr_{lr}_mom_{mom}_layers_{'_'.join(str(e) for e in filters_by_layers)}_af_relu.keras\")\n",
    "        resnet.fit(x_train,\n",
    "                        y_train,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        epochs=EPOCHS,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        shuffle=SHUFFLE,\n",
    "                        callbacks=[tf.keras.callbacks.TensorBoard(RESNET_LOG, histogram_freq=1)]\n",
    "                       ) \n",
    "        resnet.save(RESNET_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9644ca",
   "metadata": {},
   "source": [
    "##### Fonction d'activation \n",
    "Tanh Relu Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578ae3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LAYERS = list(range(3, 6))\n",
    "OPTIMIZER = SGD\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 200\n",
    "SHUFFLE = True\n",
    "learning_rates = 0.001\n",
    "momentums =  0.9\n",
    "\n",
    "def ResNet(num_layer, filters_by_layers):\n",
    "    input_layer = Input(shape=(32, 32, 3))\n",
    "    hidden_layers = input_layer\n",
    "    \n",
    "    for n in range(num_layer):\n",
    "        prev_layer = hidden_layers\n",
    "        hidden_layers = Conv2D(filters_by_layers[n], (3, 3), padding='same', activation=tanh,\n",
    "                                            kernel_initializer=he_normal)(hidden_layers)\n",
    "        #hidden_layers = Dropout(0.2)(hidden_layers)\n",
    "        if n > 0:\n",
    "            hidden_layers = Average()([hidden_layers, prev_layer])\n",
    "        else:\n",
    "            hidden_layers = Average()([hidden_layers, Dense(32)(prev_layer)])\n",
    "    \n",
    "    hidden_layers = Flatten()(hidden_layers)   \n",
    "    output_layer = Dense(NUM_CLASSES, activation=softmax)(hidden_layers)\n",
    "    return Model(input_layer, output_layer)\n",
    "\n",
    "\n",
    "num_layer = int(np.random.choice(NUM_LAYERS, 1))\n",
    "filters_by_layers = [32 for x in range(1, num_layer+1)]\n",
    "\n",
    "resnet = ResNet(num_layer, filters_by_layers)\n",
    "resnet.compile(loss=categorical_crossentropy,\n",
    "            optimizer=SGD(lr, momentum=mom),\n",
    "            metrics=categorical_accuracy)\n",
    "RESNET_LOG = os.path.join(LOG_DIR, \"resnet\",\n",
    "                f\"resnet_ep_{EPOCHS}_bs_{BATCH_SIZE}_opt_SGD_lr_{learning_rates}_mom_{momentums}_layers_{'_'.join(str(e) for e in filters_by_layers)}_af_tanh\")\n",
    "RESNET_MODEL = os.path.join(MODEL_DIR, \"resnet\",\n",
    "                f\"resnet_ep_{EPOCHS}_bs_{BATCH_SIZE}_opt_SGD_lr_{learning_rates}_mom_{momentums}_layers_{'_'.join(str(e) for e in filters_by_layers)}_af_tanh.keras\")\n",
    "resnet.fit(x_train,\n",
    "                y_train,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                epochs=EPOCHS,\n",
    "                validation_data=(x_test, y_test),\n",
    "                shuffle=SHUFFLE,\n",
    "                callbacks=[tf.keras.callbacks.TensorBoard(RESNET_LOG, histogram_freq=1)]\n",
    "               ) \n",
    "resnet.save(RESNET_MODEL)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec2d781d",
   "metadata": {},
   "source": [
    "NUM_LAYERS = list(range(3, 6))\n",
    "OPTIMIZER = SGD\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 200\n",
    "SHUFFLE = True\n",
    "learning_rates = 0.001\n",
    "momentums = 0.9\n",
    "\n",
    "def ResNet(num_layer, filters_by_layers):\n",
    "    input_layer = Input(shape=(32, 32, 3))\n",
    "    hidden_layers = input_layer\n",
    "    \n",
    "    for n in range(num_layer):\n",
    "        prev_layer = hidden_layers\n",
    "        hidden_layers = Conv2D(filters_by_layers[n], (3, 3), padding='same', activation=relu,\n",
    "                                            kernel_initializer=he_normal)(hidden_layers)\n",
    "        #hidden_layers = Dropout(0.2)(hidden_layers)\n",
    "        if n > 0:\n",
    "            hidden_layers = Average()([hidden_layers, prev_layer])\n",
    "        else:\n",
    "            hidden_layers = Average()([hidden_layers, Dense(32)(prev_layer)])\n",
    "    \n",
    "    hidden_layers = Flatten()(hidden_layers)   \n",
    "    output_layer = Dense(NUM_CLASSES, activation=softmax)(hidden_layers)\n",
    "    return Model(input_layer, output_layer)\n",
    "\n",
    "\n",
    "num_layer = int(np.random.choice(NUM_LAYERS, 1))\n",
    "filters_by_layers = [32 for x in range(1, num_layer+1)]\n",
    "\n",
    "resnet = ResNet(num_layer, filters_by_layers)\n",
    "resnet.compile(loss=categorical_crossentropy,\n",
    "            optimizer=SGD(learning_rates, momentum=momentums),\n",
    "            metrics=categorical_accuracy)\n",
    "RESNET_LOG = os.path.join(LOG_DIR, \"resnet\",\n",
    "                f\"resnet_ep_{EPOCHS}_bs_{BATCH_SIZE}_opt_SGD_lr_{learning_rates}_mom_{momentums}_layers_{'_'.join(str(e) for e in filters_by_layers)}_af_relu\")\n",
    "RESNET_MODEL = os.path.join(MODEL_DIR, \"resnet\",\n",
    "                f\"resnet_ep_{EPOCHS}_bs_{BATCH_SIZE}_opt_{OPTIMIZER}_lr_{learning_rates}_mom_{momentums}_layers_{'_'.join(str(e) for e in filters_by_layers)}_af_relu.keras\")\n",
    "resnet.fit(x_train,\n",
    "                y_train,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                epochs=EPOCHS,\n",
    "                validation_data=(x_test, y_test),\n",
    "                shuffle=SHUFFLE,\n",
    "                callbacks=[tf.keras.callbacks.TensorBoard(RESNET_LOG, histogram_freq=1)]\n",
    "               ) \n",
    "resnet.save(RESNET_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578051a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LAYERS = list(range(3, 6))\n",
    "OPTIMIZER = SGD\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 200\n",
    "SHUFFLE = True\n",
    "learning_rates = 0.001\n",
    "momentums = 0.9\n",
    "\n",
    "def ResNet(num_layer, filters_by_layers):\n",
    "    input_layer = Input(shape=(32, 32, 3))\n",
    "    hidden_layers = input_layer\n",
    "    \n",
    "    for n in range(num_layer):\n",
    "        prev_layer = hidden_layers\n",
    "        hidden_layers = Conv2D(filters_by_layers[n], (3, 3), padding='same', activation=sigmoid,\n",
    "                                            kernel_initializer=he_normal)(hidden_layers)\n",
    "        #hidden_layers = Dropout(0.2)(hidden_layers)\n",
    "        if n > 0:\n",
    "            hidden_layers = Average()([hidden_layers, prev_layer])\n",
    "        else:\n",
    "            hidden_layers = Average()([hidden_layers, Dense(32)(prev_layer)])\n",
    "    \n",
    "    hidden_layers = Flatten()(hidden_layers)   \n",
    "    output_layer = Dense(NUM_CLASSES, activation=softmax)(hidden_layers)\n",
    "    return Model(input_layer, output_layer)\n",
    "\n",
    "\n",
    "num_layer = int(np.random.choice(NUM_LAYERS, 1))\n",
    "filters_by_layers = [32 for x in range(1, num_layer+1)]\n",
    "\n",
    "resnet = ResNet(num_layer, filters_by_layers)\n",
    "resnet.compile(loss=categorical_crossentropy,\n",
    "            optimizer=SGD(learning_rates, momentum=momentums),\n",
    "            metrics=categorical_accuracy)\n",
    "RESNET_LOG = os.path.join(LOG_DIR, \"resnet\",\n",
    "                f\"resnet_ep_{EPOCHS}_bs_{BATCH_SIZE}_opt_SGD_lr_{learning_rates}_mom_{momentums}_layers_{'_'.join(str(e) for e in filters_by_layers)}_af_sigmoid\")\n",
    "RESNET_MODEL = os.path.join(MODEL_DIR, \"resnet\",\n",
    "                f\"resnet_ep_{EPOCHS}_bs_{BATCH_SIZE}_opt_SGD_lr_{learning_rates}_mom_{momentums}_layers_{'_'.join(str(e) for e in filters_by_layers)}_af_sigmoid.keras\")\n",
    "resnet.fit(x_train,\n",
    "                y_train,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                epochs=EPOCHS,\n",
    "                validation_data=(x_test, y_test),\n",
    "                shuffle=SHUFFLE,\n",
    "                callbacks=[tf.keras.callbacks.TensorBoard(RESNET_LOG, histogram_freq=1)]\n",
    "               ) \n",
    "resnet.save(RESNET_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ca8485",
   "metadata": {},
   "source": [
    "##### Optimizer \n",
    "SGD ADAM RMSprop"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fd73d5cc",
   "metadata": {},
   "source": [
    "NUM_LAYERS = list(range(3, 6))\n",
    "OPTIMIZER = SGD\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 200\n",
    "SHUFFLE = True\n",
    "learning_rates = 0.001\n",
    "momentums = 0.9\n",
    "\n",
    "def ResNet(num_layer, filters_by_layers):\n",
    "    input_layer = Input(shape=(32, 32, 3))\n",
    "    hidden_layers = input_layer\n",
    "    \n",
    "    for n in range(num_layer):\n",
    "        prev_layer = hidden_layers\n",
    "        hidden_layers = Conv2D(filters_by_layers[n], (3, 3), padding='same', activation=relu,\n",
    "                                            kernel_initializer=he_normal)(hidden_layers)\n",
    "        #hidden_layers = Dropout(0.2)(hidden_layers)\n",
    "        if n > 0:\n",
    "            hidden_layers = Average()([hidden_layers, prev_layer])\n",
    "        else:\n",
    "            hidden_layers = Average()([hidden_layers, Dense(32)(prev_layer)])\n",
    "    \n",
    "    hidden_layers = Flatten()(hidden_layers)   \n",
    "    output_layer = Dense(NUM_CLASSES, activation=softmax)(hidden_layers)\n",
    "    return Model(input_layer, output_layer)\n",
    "\n",
    "\n",
    "num_layer = int(np.random.choice(NUM_LAYERS, 1))\n",
    "filters_by_layers = [32 for x in range(1, num_layer+1)]\n",
    "\n",
    "resnet = ResNet(num_layer, filters_by_layers)\n",
    "resnet.compile(loss=categorical_crossentropy,\n",
    "            optimizer=SGD(learning_rates, momentum=momentums),\n",
    "            metrics=categorical_accuracy)\n",
    "RESNET_LOG = os.path.join(LOG_DIR, \"resnet\", f\"resnet_ep_{EPOCHS}_bs_{BATCH_SIZE}_opt_{OPTIMIZER}_lr_{learning_rates}_mom_{momentums}_layers_{'_'.join(str(e) for e in filters_by_layers)}_af_relu\")\n",
    "resnet.fit(x_train,\n",
    "                y_train,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                epochs=EPOCHS,\n",
    "                validation_data=(x_test, y_test),\n",
    "                shuffle=SHUFFLE,\n",
    "                callbacks=[tf.keras.callbacks.TensorBoard(RESNET_LOG, histogram_freq=1)]\n",
    "               ) \n",
    "convnet.save(CONVNET_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485d70b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LAYERS = list(range(3, 6))\n",
    "OPTIMIZER = Adam\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 200\n",
    "SHUFFLE = True\n",
    "learning_rates = 0.001\n",
    "momentums = 0.9\n",
    "\n",
    "def ResNet(num_layer, filters_by_layers):\n",
    "    input_layer = Input(shape=(32, 32, 3))\n",
    "    hidden_layers = input_layer\n",
    "    \n",
    "    for n in range(num_layer):\n",
    "        prev_layer = hidden_layers\n",
    "        hidden_layers = Conv2D(filters_by_layers[n], (3, 3), padding='same', activation=relu,\n",
    "                                            kernel_initializer=he_normal)(hidden_layers)\n",
    "        #hidden_layers = Dropout(0.2)(hidden_layers)\n",
    "        if n > 0:\n",
    "            hidden_layers = Average()([hidden_layers, prev_layer])\n",
    "        else:\n",
    "            hidden_layers = Average()([hidden_layers, Dense(32)(prev_layer)])\n",
    "    \n",
    "    hidden_layers = Flatten()(hidden_layers)   \n",
    "    output_layer = Dense(NUM_CLASSES, activation=softmax)(hidden_layers)\n",
    "    return Model(input_layer, output_layer)\n",
    "\n",
    "\n",
    "num_layer = int(np.random.choice(NUM_LAYERS, 1))\n",
    "filters_by_layers = [32 for x in range(1, num_layer+1)]\n",
    "\n",
    "resnet = ResNet(num_layer, filters_by_layers)\n",
    "resnet.compile(loss=categorical_crossentropy,\n",
    "            optimizer=SGD(learning_rates),\n",
    "            metrics=categorical_accuracy)\n",
    "RESNET_LOG = os.path.join(LOG_DIR, \"resnet\",\n",
    "                f\"resnet_ep_{EPOCHS}_bs_{BATCH_SIZE}_opt_Adam_lr_{learning_rates}_mom_{momentums}_layers_{'_'.join(str(e) for e in filters_by_layers)}_af_relu\")\n",
    "RESNET_MODEL = os.path.join(MODEL_DIR, \"resnet\",\n",
    "                f\"resnet_ep_{EPOCHS}_bs_{BATCH_SIZE}_opt_Adam_lr_{learning_rates}_mom_{momentums}_layers_{'_'.join(str(e) for e in filters_by_layers)}_af_relu.keras\")\n",
    "resnet.fit(x_train,\n",
    "                y_train,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                epochs=EPOCHS,\n",
    "                validation_data=(x_test, y_test),\n",
    "                shuffle=SHUFFLE,\n",
    "                callbacks=[tf.keras.callbacks.TensorBoard(RESNET_LOG, histogram_freq=1)]\n",
    "               ) \n",
    "resnet.save(RESNET_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22784002",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LAYERS = list(range(3, 6))\n",
    "OPTIMIZER = RMSprop\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 200\n",
    "SHUFFLE = True\n",
    "learning_rates = 0.001\n",
    "momentums = 0.9\n",
    "\n",
    "def ResNet(num_layer, filters_by_layers):\n",
    "    input_layer = Input(shape=(32, 32, 3))\n",
    "    hidden_layers = input_layer\n",
    "    \n",
    "    for n in range(num_layer):\n",
    "        prev_layer = hidden_layers\n",
    "        hidden_layers = Conv2D(filters_by_layers[n], (3, 3), padding='same', activation=relu,\n",
    "                                            kernel_initializer=he_normal)(hidden_layers)\n",
    "        #hidden_layers = Dropout(0.2)(hidden_layers)\n",
    "        if n > 0:\n",
    "            hidden_layers = Average()([hidden_layers, prev_layer])\n",
    "        else:\n",
    "            hidden_layers = Average()([hidden_layers, Dense(32)(prev_layer)])\n",
    "    \n",
    "    hidden_layers = Flatten()(hidden_layers)   \n",
    "    output_layer = Dense(NUM_CLASSES, activation=softmax)(hidden_layers)\n",
    "    return Model(input_layer, output_layer)\n",
    "\n",
    "\n",
    "num_layer = int(np.random.choice(NUM_LAYERS, 1))\n",
    "filters_by_layers = [32 for x in range(1, num_layer+1)]\n",
    "\n",
    "resnet = ResNet(num_layer, filters_by_layers)\n",
    "resnet.compile(loss=categorical_crossentropy,\n",
    "            optimizer=RMSprop(learning_rates, momentum=momentums),\n",
    "            metrics=categorical_accuracy)\n",
    "RESNET_LOG = os.path.join(LOG_DIR, \"resnet\", f\"resnet_ep_{EPOCHS}_bs_{BATCH_SIZE}_opt_RMSprop_lr_{learning_rates}_mom_{momentums}_layers_{'_'.join(str(e) for e in filters_by_layers)}_af_relu\")\n",
    "RESNET_MODEL = os.path.join(MODEL_DIR, \"resnet\",\n",
    "                f\"resnet_ep_{EPOCHS}_bs_{BATCH_SIZE}_opt_RMSprop_lr_{learning_rates}_mom_{momentums}_layers_{'_'.join(str(e) for e in filters_by_layers)}_af_relu.keras\")\n",
    "resnet.fit(x_train,\n",
    "                y_train,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                epochs=EPOCHS,\n",
    "                validation_data=(x_test, y_test),\n",
    "                shuffle=SHUFFLE,\n",
    "                callbacks=[tf.keras.callbacks.TensorBoard(RESNET_LOG, histogram_freq=1)]\n",
    "               ) \n",
    "resnet.save(RESNET_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f93f07",
   "metadata": {},
   "source": [
    "#### Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56092adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LAYERS = list(range(3, 6))\n",
    "OPTIMIZER = SGD\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 200\n",
    "SHUFFLE = True\n",
    "learning_rates = 0.001\n",
    "momentums = 0.9\n",
    "\n",
    "def ResNet(num_layer, filters_by_layers):\n",
    "    input_layer = Input(shape=(32, 32, 3))\n",
    "    hidden_layers = input_layer\n",
    "    \n",
    "    for n in range(num_layer):\n",
    "        prev_layer = hidden_layers\n",
    "        hidden_layers = Conv2D(filters_by_layers[n], (3, 3), padding='same', activation=relu,\n",
    "                                            kernel_initializer=he_normal)(hidden_layers)\n",
    "        #hidden_layers = Dropout(0.2)(hidden_layers)\n",
    "        if n > 0:\n",
    "            hidden_layers = Average()([hidden_layers, prev_layer])\n",
    "        else:\n",
    "            hidden_layers = Average()([hidden_layers, Dense(32)(prev_layer)])\n",
    "    \n",
    "    hidden_layers = Flatten()(hidden_layers)   \n",
    "    output_layer = Dense(NUM_CLASSES, activation=softmax,kernel_regularizer=l2(0.5), bias_regularizer=l2(0.5))(hidden_layers)\n",
    "    return Model(input_layer, output_layer)\n",
    "\n",
    "\n",
    "num_layer = int(np.random.choice(NUM_LAYERS, 1))\n",
    "filters_by_layers = [32 for x in range(1, num_layer+1)]\n",
    "\n",
    "resnet = ResNet(num_layer, filters_by_layers)\n",
    "resnet.compile(loss=categorical_crossentropy,\n",
    "            optimizer=SGD(learning_rates, momentum=momentums),\n",
    "            metrics=categorical_accuracy)\n",
    "RESNET_LOG = os.path.join(LOG_DIR, \"resnet\", f\"resnet_ep_{EPOCHS}_bs_{BATCH_SIZE}_opt_SGD_lr_{learning_rates}_mom_{momentums}_layers_{'_'.join(str(e) for e in filters_by_layers)}_af_relu_l20.5\")\n",
    "RESNET_MODEL = os.path.join(MODEL_DIR, \"resnet\",\n",
    "                f\"resnet_ep_{EPOCHS}_bs_{BATCH_SIZE}_opt_SGD_lr_{learning_rates}_mom_{momentums}_layers_{'_'.join(str(e) for e in filters_by_layers)}_af_relu_l20.5.keras\")\n",
    "resnet.fit(x_train,\n",
    "                y_train,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                epochs=EPOCHS,\n",
    "                validation_data=(x_test, y_test),\n",
    "                shuffle=SHUFFLE,\n",
    "                callbacks=[tf.keras.callbacks.TensorBoard(RESNET_LOG, histogram_freq=1)]\n",
    "               ) \n",
    "resnet.save(RESNET_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c7b13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LAYERS = list(range(3, 6))\n",
    "OPTIMIZER = SGD\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 200\n",
    "SHUFFLE = True\n",
    "learning_rates = 0.001\n",
    "momentums = 0.9\n",
    "\n",
    "def ResNet(num_layer, filters_by_layers):\n",
    "    input_layer = Input(shape=(32, 32, 3))\n",
    "    hidden_layers = input_layer\n",
    "    \n",
    "    for n in range(num_layer):\n",
    "        prev_layer = hidden_layers\n",
    "        hidden_layers = Conv2D(filters_by_layers[n], (3, 3), padding='same', activation=relu,\n",
    "                                            kernel_initializer=he_normal)(hidden_layers)\n",
    "        #hidden_layers = Dropout(0.2)(hidden_layers)\n",
    "        if n > 0:\n",
    "            hidden_layers = Average()([hidden_layers, prev_layer])\n",
    "        else:\n",
    "            hidden_layers = Average()([hidden_layers, Dense(32)(prev_layer)])\n",
    "    \n",
    "    hidden_layers = Flatten()(hidden_layers)   \n",
    "    output_layer = Dense(NUM_CLASSES, activation=softmax,kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(hidden_layers)\n",
    "    return Model(input_layer, output_layer)\n",
    "\n",
    "\n",
    "num_layer = int(np.random.choice(NUM_LAYERS, 1))\n",
    "filters_by_layers = [32 for x in range(1, num_layer+1)]\n",
    "\n",
    "resnet = ResNet(num_layer, filters_by_layers)\n",
    "resnet.compile(loss=categorical_crossentropy,\n",
    "            optimizer=SGD(learning_rates, momentum=momentums),\n",
    "            metrics=categorical_accuracy)\n",
    "RESNET_LOG = os.path.join(LOG_DIR, \"resnet\", f\"resnet_ep_{EPOCHS}_bs_{BATCH_SIZE}_opt_SGD_lr_{learning_rates}_mom_{momentums}_layers_{'_'.join(str(e) for e in filters_by_layers)}_af_relu_l20.01\")\n",
    "RESNET_MODEL = os.path.join(MODEL_DIR, \"resnet\",\n",
    "                f\"resnet_ep_{EPOCHS}_bs_{BATCH_SIZE}_opt_SGD_lr_{learning_rates}_mom_{momentums}_layers_{'_'.join(str(e) for e in filters_by_layers)}_af_relu_l20.01.keras\")\n",
    "resnet.fit(x_train,\n",
    "                y_train,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                epochs=EPOCHS,\n",
    "                validation_data=(x_test, y_test),\n",
    "                shuffle=SHUFFLE,\n",
    "                callbacks=[tf.keras.callbacks.TensorBoard(RESNET_LOG, histogram_freq=1)]\n",
    "               ) \n",
    "resnet.save(RESNET_MODEL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
