{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c14d082c-b9bd-4d36-9039-92005273c9c8",
   "metadata": {},
   "source": [
    "# CIFAR-10\n",
    "\n",
    "La première étape intermédiaire de notre projet est d'utiliser les algorithmes ci-dessous sur le célébre dataset CIFAR-10.\n",
    "\n",
    "\n",
    "Il faut :\n",
    "1. L'influence de tous les hyperparamètres des modèles\n",
    "    - Structure\n",
    "    - Fonctions d'activations\n",
    "    - etc.\n",
    "2. Les paramètres des algorithmes d'apprentissages\n",
    "    - Learning Rate\n",
    "    - Momentum\n",
    "    - etc.\n",
    "    \n",
    "----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e378f01b-f353-4e9b-8a80-73c9b83f6bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from numpy.random import seed\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, BatchNormalization, Input, Average, MaxPool2D, Dropout\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.activations import relu, softmax, tanh\n",
    "from tensorflow.keras.initializers import he_normal, glorot_uniform, Zeros\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.regularizers import l2, l1, l1_l2\n",
    "from tensorflow.random import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5f4e0a-0bbb-4378-a289-d8646e065ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Version de TensorFlow :\", tf.__version__)\n",
    "print(\"Nom du GPU :\", tf.test.gpu_device_name())\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tf.config.optimizer.set_jit(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9a71ea-ca82-439e-8f2e-8ecef5e0e192",
   "metadata": {},
   "source": [
    "## Importation du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefc0c44-22d0-497f-affc-949cde51e72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd58edc-df9b-49ed-ab39-9572fa1ed97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "IMG_SIZE = x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ff4114-34f9-4e83-9ee2-a934a53403c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 256\n",
    "x_test = x_test.astype('float32') / 256\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "y_test = to_categorical(y_test, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850b786e-e2ab-40b1-b5cc-b5cdf5125b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = os.path.join(\"logs\")\n",
    "MODELS_DIR = os.path.join(\"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc27c2c",
   "metadata": {},
   "source": [
    "## Fixer les seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff124095",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42) # TensorFlow\n",
    "seed(42) # NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85284b88",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68442913-a7c8-4c79-873a-b009912ba59b",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6507baf4",
   "metadata": {},
   "source": [
    "Pour voir l'influence des hyperparamètres sur un MLP, nous avons d'abord besoin de fixer le nombre d'époques et le nombre de layer sur notre couche de sortie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ea9914",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 500\n",
    "SHUFFLE = True\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1a19a9",
   "metadata": {},
   "source": [
    "Pour nous faciliter la tâche, nous allons créer un modèle principal appelé *main* puis nous allons ajouter, modifier ou enlever un hyperparamètre à la fois pour que l'on puisse aperçevoir son influence sur le modèle. Pour chacun des hyperparamètres déjà présent dans notre modèle principal, nous allons prendre une valeur excessivement élevè et une valeur très basse. En revanche, pour les hyperparamètres qui n'y s'y trouvent pas (ex: Dropout, L2), nous allons les ajouter à notre modèle et comparer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07dbe72",
   "metadata": {},
   "source": [
    "## Modèle main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77e3954",
   "metadata": {},
   "source": [
    "Le modèle `main` est notre modèle principale, ce sera celui avec lequelle nous comparerons tout les autres prochains modèles et essayer de distinguer le plus clairement possible l'influence des hyperparamètres que nous modifierons. Nous avons choisi les hyperparamètres par défaut lorsque c'était possible et avons choisi le reste selon notre intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac6b5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_main(num_layer: int, nodes_by_layers: List[int]) -> Model:\n",
    "    input_layer = Input(shape=(32, 32, 3))\n",
    "    hidden_layers = Flatten()(input_layer)\n",
    "    \n",
    "    for n in range(num_layer):\n",
    "        hidden_layers = Dense(nodes_by_layers[n], activation=relu, kernel_initializer=he_normal)(hidden_layers)\n",
    "        \n",
    "    output_layer = Dense(NUM_CLASSES, activation=softmax)(hidden_layers)\n",
    "    return Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f113bf7",
   "metadata": {},
   "source": [
    "Voici les hyperparamètres de notre modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7567c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_layer = 6\n",
    "nodes_by_layers = [32, 16, 64, 32, 16, 64]\n",
    "learning_rate = 0.01\n",
    "momentum = 0.45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b945ace0",
   "metadata": {},
   "source": [
    "Tout au long de notre section sur le MLP, nous n'utiliserons comme optimiseur uniquement Stochastic Gradient Descent (SGD). Nous pouvons désormais instancier et entraîner notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc6603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP_main(num_layer, nodes_by_layers)\n",
    "\n",
    "mlp.compile(\n",
    "    loss=categorical_crossentropy,\n",
    "    optimizer=SGD(learning_rate=learning_rate, momentum=momentum),\n",
    "    metrics=categorical_accuracy\n",
    "           )\n",
    "\n",
    "MLP_LOG = os.path.join(LOG_DIR, \"mlp\",\n",
    "                f\"ep_{EPOCHS}_bs_{batch_size}_opt_SGD_lr_{lr}_mom_{mom}_af_relu_layers_{'_'.join(str(e) for e in nodes_by_layers)}_main\")\n",
    "\n",
    "MLP_MODELS = os.path.join(MODELS_DIR, \"mlp\",\n",
    "                f\"ep_{EPOCHS}_bs_{batch_size}_opt_SGD_lr_{lr}_mom_{mom}_af_relu_layers_{'_'.join(str(e) for e in nodes_by_layers)}_main.keras\")\n",
    "\n",
    "mlp.fit(x_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(x_test, y_test),\n",
    "        shuffle=SHUFFLE,\n",
    "        callbacks=[TensorBoard(MLP_LOG)]\n",
    "       )\n",
    "mlp.save(MLP_MODELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b533662",
   "metadata": {},
   "source": [
    "Regardons la courbe de loss et d'accuracy de notre modèle principal. \n",
    "\n",
    "En bleu, les courbes sur les données de validation. Et en orange, les courbe sur les données d'entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7bb917",
   "metadata": {},
   "source": [
    "![Accuracy](images/MLP_main_accuracy.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f99b97",
   "metadata": {},
   "source": [
    "On peut désormais en être sûr, notre courbe de loss nous apprend que notre modèle **sur-apprend** mais après environ 150 époques. On peut le voir car notre courbe bleu (données de validation) augmente de plus en plus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13148f39",
   "metadata": {},
   "source": [
    "![Loss_main](images/MLP_main_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e51cfa",
   "metadata": {},
   "source": [
    "Nous pouvons voir que notre modèle stagne sur nos données de validation à partir de 50 époques, ce qui signifie qu'il sur-apprend après ces 50 époques. La courbe de loss nous permettra d'en être définitivement sûr."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d0da50",
   "metadata": {},
   "source": [
    "## Nombre de couches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4166b7",
   "metadata": {},
   "source": [
    "Nous allons changer le nombre de couches de notre modèle, notre modèle initial contient 6 couches. Nous allons comparer avec un modèle à 2 puis à 20 couches pour voir l'importance de cette hyperparamètre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bde361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "learning_rate = 0.01\n",
    "momentum = 0.45\n",
    "num_layers = [2, 20]\n",
    "nodes_by_layers = [32, 16, 64, 32, 16, 64, 32, 16, 64, 32, 16, 64, 32, 16, 64, 32, 16, 64, 32, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17d8779",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, num_layer in enumerate(num_layers):\n",
    "    mlp = MLP_main(num_layer, nodes_by_layers)\n",
    "\n",
    "    mlp.compile(\n",
    "        loss=categorical_crossentropy,\n",
    "        optimizer=SGD(learning_rate=learning_rate, momentum=momentum),\n",
    "        metrics=categorical_accuracy\n",
    "               )\n",
    "\n",
    "    MLP_LOG = os.path.join(LOG_DIR, \"mlp\",\n",
    "                    f\"ep_{EPOCHS}_bs_{batch_size}_opt_SGD_lr_{learning_rate}_mom_{momentum}_af_relu_layers_{'_'.join(str(e) for e in nodes_by_layers)}_a_{i+1}\")\n",
    "\n",
    "    MLP_MODELS = os.path.join(MODELS_DIR, \"mlp\",\n",
    "                    f\"ep_{EPOCHS}_bs_{batch_size}_opt_SGD_lr_{learning_rate}_mom_{momentum}_af_relu_layers_{'_'.join(str(e) for e in nodes_by_layers)}_a_{i+1}.keras\")\n",
    "\n",
    "    mlp.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=EPOCHS,\n",
    "            validation_data=(x_test, y_test),\n",
    "            shuffle=SHUFFLE,\n",
    "            callbacks=[TensorBoard(MLP_LOG)]\n",
    "           )\n",
    "    \n",
    "    mlp.save(MLP_MODELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74d2d44",
   "metadata": {},
   "source": [
    "Comparons les courbe de loss et d'accuracy de notre modèle principal avec nos deux modèles tests.\n",
    "\n",
    "**Rappel** : En bleu foncé, les courbes du modèle principal sur les données de validation.\n",
    "\n",
    "En orange, les courbes du modèle principal sur les données d'entraînement.\n",
    "\n",
    "En bleu clair, les courbes du modèle à 2 couches cachées sur les données de validation. \n",
    "\n",
    "En rouge, les courbes du modèle à 2 couches cachées sur les données d'entraînement.\n",
    "\n",
    "En vert, les courbes du modèle à 20 couches cachées sur les données de validation. \n",
    "\n",
    "En rose, les courbes du modèle à 20 couches cachées sur les données d'entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4b3ecf",
   "metadata": {},
   "source": [
    "![Comparaison_main_couches_test](images/MLP_a_accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c63342e",
   "metadata": {},
   "source": [
    "![Comparaison_main_couches_test](images/MLP_a_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f357f2f7",
   "metadata": {},
   "source": [
    "Commençons par comparer avec le modèle à **2 couches cachées**, nous pouvons voir que sur les données de validation, ce modèle à presque les mêmes résultats que notre modèle principal. La majeur différence se fait sur les données d'entraînement où l'on peut voir que le modèle moins profond apprend moins bien que le modèle initial.\n",
    "\n",
    "Pour le modèle à **20 couches cachées**, nous pouvons voir que l'apprentissage est plus lent de manière générale, cela est dû à la profondeur du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a618aa4b",
   "metadata": {},
   "source": [
    "## Learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b721233",
   "metadata": {},
   "source": [
    "Nous allons ajuster notre taux d'apprentissage (*learning rate* en anglais) de notre modèle, notre modèle initial contient un taux d'apprentissage de 0.01 (valeur par défaut). Nous allons comparer avec un modèle ayant 0.005 puis 0.05 en taux d'apprentissage pour voir l'importance de cette hyperparamètre sur notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ceb71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "learning_rates = [0.0005, 0.05]\n",
    "momentum = 0.45\n",
    "num_layer = 6\n",
    "nodes_by_layers = [32, 16, 64, 32, 16, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d717338",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, learning_rate in enumerate(learning_rates):\n",
    "    mlp = MLP_main(num_layer, nodes_by_layers)\n",
    "    \n",
    "    mlp.compile(\n",
    "        loss=categorical_crossentropy,\n",
    "        optimizer=SGD(learning_rate=learning_rate, momentum=momentum),\n",
    "        metrics=categorical_accuracy\n",
    "    )\n",
    "    \n",
    "    MLP_LOG = os.path.join(LOG_DIR, \"mlp\",\n",
    "                    f\"ep_{EPOCHS}_bs_{batch_size}_opt_SGD_lr_{learning_rate}_mom_{momentum}_af_relu_layers_{'_'.join(str(e) for e in nodes_by_layers)}_b_{i+1}\")\n",
    "    \n",
    "    MLP_MODELS = os.path.join(MODELS_DIR, \"mlp\",\n",
    "                    f\"ep_{EPOCHS}_bs_{batch_size}_opt_SGD_lr_{learning_rate}_mom_{momentum}_af_relu_layers_{'_'.join(str(e) for e in nodes_by_layers)}_b_{i+1}.keras\")\n",
    "\n",
    "    mlp.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=EPOCHS,\n",
    "            validation_data=(x_test, y_test),\n",
    "            shuffle=SHUFFLE,\n",
    "            callbacks=[TensorBoard(MLP_LOG)]\n",
    "           )\n",
    "    \n",
    "    mlp.save(MLP_MODELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cfb8db",
   "metadata": {},
   "source": [
    "Comparons les courbe de loss et d'accuracy de notre modèle principal avec nos deux modèles tests.\n",
    "\n",
    "**Rappel** : En bleu foncé, les courbes du modèle principal sur les données de validation. \n",
    "\n",
    "En orange, les courbes du modèle principal sur les données d'entraînement.\n",
    "\n",
    "En bleu clair, les courbes du modèle ayant un taux d'apprentissage de 0.005 sur les données de validation. \n",
    "\n",
    "En rouge, les courbes du modèle ayant un taux d'apprentissage de 0.005 sur les données d'entraînement.\n",
    "\n",
    "En vert, les courbes du modèle ayant un taux d'apprentissage de 0.5 sur les données de validation. \n",
    "\n",
    "En rose, les courbes du modèle ayant un taux d'apprentissage de 0.5 sur les données d'entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702937e9",
   "metadata": {},
   "source": [
    "![Comparaison_main_learning_rate_test](images/MLP_b_accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59e7d47",
   "metadata": {},
   "source": [
    "![Comparaison_main_learning_rate_test](images/MLP_b_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cb17f7",
   "metadata": {},
   "source": [
    "Commençons par comparer avec le modèle ayant un **taux d'apprentissage de 0.005**, nous pouvons voir que ce modèle est de manière générale plus stable mais apprend plus lentement, ce qui est tout à fait normal car notre modèle réalise de tout petit pas vers le minimum local (si, on a de la chance vers minimum global).\n",
    "\n",
    "Pour le modèle ayant un **taux d'apprentissage de 0.05**, nous pouvons voir que ce modèle à un apprentissage plus instable que le modèle initial, cela est dû au fort taux d'apprentissage qui réalise des pas très grand et diverge du minimum local."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123336f7",
   "metadata": {},
   "source": [
    "## Batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3314b11",
   "metadata": {},
   "source": [
    "Nous allons changer le nombre de couches de notre modèle, notre modèle initial contient un batch size de 256. Nous allons comparer avec un modèle contenant un batch size de 32 puis de 1024 pour voir l'importance de cette hyperparamètre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15351e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [32, 1024]\n",
    "learning_rate = 0.01\n",
    "momentum = 0.45\n",
    "num_layers = 6\n",
    "nodes_by_layers = [32, 16, 64, 32, 16, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d7a4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch_size in enumerate(batch_sizes):\n",
    "    mlp = MLP_main(num_layers, nodes_by_layers)\n",
    "\n",
    "    mlp.compile(\n",
    "        loss=categorical_crossentropy,\n",
    "        optimizer=SGD(learning_rate=learning_rate, momentum=momentum),\n",
    "        metrics=categorical_accuracy\n",
    "               )\n",
    "\n",
    "    MLP_LOG = os.path.join(LOG_DIR, \"mlp\",\n",
    "                    f\"ep_{EPOCHS}_bs_{batch_size}_opt_SGD_lr_{learning_rate}_mom_{momentum}_af_relu_layers_{'_'.join(str(e) for e in nodes_by_layers)}_c_{i+1}\")\n",
    "\n",
    "    MLP_MODELS = os.path.join(MODELS_DIR, \"mlp\",\n",
    "                    f\"ep_{EPOCHS}_bs_{batch_size}_opt_SGD_lr_{learning_rate}_mom_{momentum}_af_relu_layers_{'_'.join(str(e) for e in nodes_by_layers)}_c_{i+1}.keras\")\n",
    "\n",
    "    mlp.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=EPOCHS,\n",
    "            validation_data=(x_test, y_test),\n",
    "            shuffle=SHUFFLE,\n",
    "            callbacks=[TensorBoard(MLP_LOG)]\n",
    "           )\n",
    "    mlp.save(MLP_MODELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0cabaa",
   "metadata": {},
   "source": [
    "Comparons les courbe de loss et d'accuracy de notre modèle principal avec nos deux modèles tests.\n",
    "\n",
    "**Rappel** : En bleu foncé, les courbes du modèle principal sur les données de validation. \n",
    "\n",
    "En orange, les courbes du modèle principal sur les données d'entraînement.\n",
    "\n",
    "En bleu clair, les courbes du modèle ayant un batch size de 32 sur les données de validation.\n",
    "\n",
    "En rouge, les courbes du modèle ayant un batch size de 32 sur les données d'entraînement.\n",
    "\n",
    "En vert, les courbes du modèle ayant un batch size de 1024 sur les données de validation.\n",
    "\n",
    "En rose, les courbes du modèle ayant un batch size de 1024 sur les données d'entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa7ef2f",
   "metadata": {},
   "source": [
    "![Comparaison_main_batch_test](images/MLP_c_accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e912228",
   "metadata": {},
   "source": [
    "![Comparaison_main_batch_test](images/MLP_c_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35129564",
   "metadata": {},
   "source": [
    "Commençons par comparer avec le modèle ayant un **batch size de 32**, l'apprentissage est meilleur mais beaucoup plus lent, on passe de 2 secondes pour un batch size de 256 à 11 secondes par époque. Cela est dû au découpage en batch du dataset, une époque correspond à un passage dans tout le dataset. Plus le batch size est petit, plus nous divisons le dataset en petit morceau, ce qui n'est pas très efficace si nous avons un bon GPU. On peut comparer notre cas avec un exemple plus fun, c'est comme si nous essayons d'aller de Paris à Marseille en première avec une Ferrari.\n",
    "\n",
    "Pour le modèle ayant un **batch size de 1024**, nous pouvons voir que le modèle apprend moins bien que les modèles comportant moins en batch size, car chacun des batch de notre dataset comprend moins d'images donc modifie ses poids en fonction de quelques images uniquement, ce qui rend l'apprentissage moins général et plus spécifique aux images dans le batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f032fc5",
   "metadata": {},
   "source": [
    "## Fonction d'activations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c367e237",
   "metadata": {},
   "source": [
    "Nous allons changer la fonction d'activation de toutes nos couches cachées, notre modèle initial contient comme fonction d'activation ReLU avec pour initialiseur de noyau He Normal. Nous allons comparer avec un modèle ne contenant pas de fonction d'activation avec pour initialiseur de noyau Glorot Uniform puis avec un modèle contenant comme fonction d'activation Tanh avec pour initialiseur de noyau Glorot Uniform pour voir l'importance de cette hyperparamètre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe84301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_activation_function(num_layer: int, nodes_by_layers: List[int], activation_function: str) -> Model:\n",
    "    input_layer = Input(shape=(32, 32, 3))\n",
    "    hidden_layers = Flatten()(input_layer)\n",
    "    \n",
    "    if activation_function.lower() == \"linear\":\n",
    "        for n in range(num_layer):\n",
    "            hidden_layers = Dense(nodes_by_layers[n], activation=None, kernel_initializer=glorot_uniform)(hidden_layers)\n",
    "    \n",
    "    elif activation_function.lower() == \"tanh\":\n",
    "        for n in range(num_layer):\n",
    "            hidden_layers = Dense(nodes_by_layers[n], activation=tanh, kernel_initializer=glorot_uniform)(hidden_layers)\n",
    "    \n",
    "    else:\n",
    "        for n in range(num_layer):\n",
    "            hidden_layers = Dense(nodes_by_layers[n], activation=relu, kernel_initializer=he_normal)(hidden_layers)\n",
    "    \n",
    "    output_layer = Dense(NUM_CLASSES, activation=softmax)(hidden_layers)\n",
    "    return Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904d09f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "learning_rate = 0.01\n",
    "momentum = 0.45\n",
    "num_layers = 6\n",
    "nodes_by_layers = [32, 16, 64, 32, 16, 64]\n",
    "activation_functions = [\"linear\", \"tanh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641759c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, activation_function in enumerate(activation_functions):\n",
    "    mlp = MLP_activation_function(num_layers, nodes_by_layers, activation_function)\n",
    "\n",
    "    mlp.compile(\n",
    "        loss=categorical_crossentropy,\n",
    "        optimizer=SGD(learning_rate=learning_rate, momentum=momentum),\n",
    "        metrics=categorical_accuracy\n",
    "               )\n",
    "\n",
    "    MLP_LOG = os.path.join(LOG_DIR, \"mlp\",\n",
    "                    f\"ep_{EPOCHS}_bs_{batch_size}_opt_SGD_lr_{learning_rate}_mom_{momentum}_af_{activation_function}_layers_{'_'.join(str(e) for e in nodes_by_layers)}_d_{i+1}\")\n",
    "\n",
    "    MLP_MODELS = os.path.join(MODELS_DIR, \"mlp\",\n",
    "                    f\"ep_{EPOCHS}_bs_{batch_size}_opt_SGD_lr_{learning_rate}_mom_{momentum}_af_{activation_function}_layers_{'_'.join(str(e) for e in nodes_by_layers)}_d_{i+1}.keras\")\n",
    "\n",
    "    mlp.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=EPOCHS,\n",
    "            validation_data=(x_test, y_test),\n",
    "            shuffle=SHUFFLE,\n",
    "            callbacks=[TensorBoard(MLP_LOG)]\n",
    "           )\n",
    "    mlp.save(MLP_MODELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76438cfc",
   "metadata": {},
   "source": [
    "Comparons les courbe de loss et d'accuracy de notre modèle principal avec nos deux modèles tests.\n",
    "\n",
    "**Rappel** : En bleu foncé, les courbes du modèle principal sur les données de validation. \n",
    "\n",
    "En orange, les courbes du modèle principal sur les données d'entraînement.\n",
    "\n",
    "En bleu clair, les courbes du modèle n'ayant pas de fonction d'activation sur les données de validation.\n",
    "\n",
    "En rouge, les courbes du modèle n'ayant pas de fonction d'activation sur les données d'entraînement.\n",
    "\n",
    "En vert, les courbes du modèle ayant comme fonction d'activation Tanh sur les données de validation.\n",
    "\n",
    "En rose, les courbes du modèle ayant comme fonction d'activation Tanh sur les données d'entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c92a2ae",
   "metadata": {},
   "source": [
    "![Comparaison_main_af_test](images/MLP_d_accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc44ca8a",
   "metadata": {},
   "source": [
    "![Comparaison_main_af_test](images/MLP_d_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24976945",
   "metadata": {},
   "source": [
    "Commençons par comparer avec le modèle ayant comme **fonction d'activation Tanh**, nous pouvons voir que l'apprentissage est quasiment similaire à notre modèle initial.\n",
    "\n",
    "Pour le modèle n'ayant **pas de fonction d'activation**, on peut voir que l'apprentissage est stable mais beaucoup moins efficace. On peut en déduire que la fonction d'activation joue un rôle important dans l'accuracy d'un modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd4d6d7",
   "metadata": {},
   "source": [
    "## Momentums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff67e023",
   "metadata": {},
   "source": [
    "Nous allons changer la valeur du momentum de notre optimiseur, notre modèle initial contient 0.45 en momentum. Nous allons comparer avec un modèle n'en contenant pas puis avec un modèle contenant un très fort momentum (0.95) pour voir l'importance de cette hyperparamètre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7f41dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "learning_rate = 0.01\n",
    "momentums = [0, 0.95]\n",
    "num_layers = 6\n",
    "nodes_by_layers = [32, 16, 64, 32, 16, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384d9e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, momentum in enumerate(momentums):\n",
    "    mlp = MLP_main(num_layers, nodes_by_layers)\n",
    "\n",
    "    mlp.compile(\n",
    "        loss=categorical_crossentropy,\n",
    "        optimizer=SGD(learning_rate=learning_rate, momentum=momentum),\n",
    "        metrics=categorical_accuracy\n",
    "               )\n",
    "\n",
    "    MLP_LOG = os.path.join(LOG_DIR, \"mlp\",\n",
    "                    f\"ep_{EPOCHS}_bs_{batch_size}_opt_SGD_lr_{learning_rate}_mom_{momentum}_af_relu_layers_{'_'.join(str(e) for e in nodes_by_layers)}_e_{i+1}\")\n",
    "\n",
    "    MLP_MODELS = os.path.join(MODELS_DIR, \"mlp\",\n",
    "                    f\"ep_{EPOCHS}_bs_{batch_size}_opt_SGD_lr_{learning_rate}_mom_{momentum}_af_relu_layers_{'_'.join(str(e) for e in nodes_by_layers)}_e_{i+1}.keras\")\n",
    "\n",
    "    mlp.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=EPOCHS,\n",
    "            validation_data=(x_test, y_test),\n",
    "            shuffle=SHUFFLE,\n",
    "            callbacks=[TensorBoard(MLP_LOG)]\n",
    "           )\n",
    "    \n",
    "    mlp.save(MLP_MODELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6324f37",
   "metadata": {},
   "source": [
    "Comparons les courbe de loss et d'accuracy de notre modèle principal avec nos deux modèles tests.\n",
    "\n",
    "**Rappel** : En bleu foncé, les courbes du modèle principal sur les données de validation. \n",
    "\n",
    "En orange, les courbes du modèle principal sur les données d'entraînement.\n",
    "\n",
    "En bleu clair, les courbes du modèle n'ayant pas de momentum sur les données de validation.\n",
    "\n",
    "En rouge, les courbes du modèle n'ayant pas de momentum sur les données d'entraînement.\n",
    "\n",
    "En vert, les courbes du modèle ayant un momentum de 0.95 sur les données de validation.\n",
    "\n",
    "En rose, les courbes du modèle ayant un momentum de 0.95 sur les données d'entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b3db8f",
   "metadata": {},
   "source": [
    "![Comparaison_main_mom_test](images/MLP_e_accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0f920b",
   "metadata": {},
   "source": [
    "![Comparaison_main_mom_test](images/MLP_e_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eab65c8",
   "metadata": {},
   "source": [
    "Commençons par comparer avec le modèle n'ayant **pas de momentum**, nous pouvons voir que l'apprentissage est moins performant.\n",
    "\n",
    "Pour le modèle ayant un **momentum de 0.95**, nous pouvons remarquer l'apprentissage est encore pire que lorsque nous n'avons pas de momentum. Le modèle se base beaucoup trop sur ses directions précedentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e661a62d",
   "metadata": {},
   "source": [
    "## Norme L2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452d0803",
   "metadata": {},
   "source": [
    "Nous allons ajouter de la régularisation (norme L2) sur notre modèle, notre modèle initial n'en contient pas. Nous allons comparer avec un modèle contenant un L2 à 0.01 puis avec un modèle contenant un L2 à 0.5 pour voir l'importance de cette hyperparamètre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ef9202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_l2(num_layer: int, nodes_by_layers: List[int], l2_val: float) -> Model:\n",
    "    input_layer = Input(shape=(32, 32, 3))\n",
    "    hidden_layers = Flatten()(input_layer)\n",
    "    \n",
    "    for n in range(num_layer):\n",
    "            hidden_layers = Dense(nodes_by_layers[n], activation=relu, kernel_initializer=he_normal)(hidden_layers)\n",
    "        \n",
    "    output_layer = Dense(NUM_CLASSES, activation=softmax,\n",
    "                         kernel_regularizer=l2(l2_val), bias_regularizer=l2(l2_val))(hidden_layers)\n",
    "    return Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b7bae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "learning_rate = 0.01\n",
    "momentum = 0.45\n",
    "num_layers = 6\n",
    "nodes_by_layers = [32, 16, 64, 32, 16, 64]\n",
    "l2_vals = [0.01, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90352639",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, l2_val in enumerate(l2_vals):\n",
    "    mlp = MLP_l2(num_layers, nodes_by_layers, l2_val)\n",
    "\n",
    "    mlp.compile(\n",
    "        loss=categorical_crossentropy,\n",
    "        optimizer=SGD(learning_rate=learning_rate, momentum=momentum),\n",
    "        metrics=categorical_accuracy\n",
    "               )\n",
    "\n",
    "    MLP_LOG = os.path.join(LOG_DIR, \"mlp\",\n",
    "                    f\"ep_{EPOCHS}_bs_{batch_size}_opt_SGD_lr_{learning_rate}_mom_{momentum}_af_relu_layers_{'_'.join(str(e) for e in nodes_by_layers)}_l2_{l2_val}_f_{i+1}\")\n",
    "\n",
    "    MLP_MODELS = os.path.join(MODELS_DIR, \"mlp\",\n",
    "                    f\"ep_{EPOCHS}_bs_{batch_size}_opt_SGD_lr_{learning_rate}_mom_{momentum}_af_relu_layers_{'_'.join(str(e) for e in nodes_by_layers)}_l2_{l2_val}_f_{i+1}.keras\")\n",
    "\n",
    "    mlp.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=EPOCHS,\n",
    "            validation_data=(x_test, y_test),\n",
    "            shuffle=SHUFFLE,\n",
    "            callbacks=[TensorBoard(MLP_LOG)]\n",
    "           )\n",
    "    mlp.save(MLP_MODELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ceb20e",
   "metadata": {},
   "source": [
    "Comparons les courbe de loss et d'accuracy de notre modèle principal avec nos deux modèles tests.\n",
    "\n",
    "**Rappel** : En bleu foncé, les courbes du modèle principal sur les données de validation. \n",
    "\n",
    "En orange, les courbes du modèle principal sur les données d'entraînement.\n",
    "\n",
    "En bleu clair, les courbes du modèle ayant un L2 à 0.01 sur les données de validation.\n",
    "\n",
    "En rouge, les courbes du modèle ayant un L2 à 0.01 sur les données d'entraînement.\n",
    "\n",
    "En vert, les courbes du modèle ayant un L2 à 0.5 sur les données de validation.\n",
    "\n",
    "En rose, les courbes du modèle ayant un L2 à 0.5 sur les données d'entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0648a44",
   "metadata": {},
   "source": [
    "![Comparaison_main_l2_test](images/MLP_f_accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9fe06e",
   "metadata": {},
   "source": [
    "![Comparaison_main_l2_test](images/MLP_f_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2399e1d2",
   "metadata": {},
   "source": [
    "Commençons par comparer avec le modèle ayant un **L2 de 0.01**, nous pouvons voir que le modèle performe légérement moins bien que le modèle initial. L'effet de la norme L2 est beaucoup trop faible pour réellement impacté le modèle test.\n",
    "\n",
    "Pour le modèle ayant un **L2 de 0.5**, nous pouvons voir que le modèle commence à sur-apprendre plus tard que nos deux modèles (vers 225 époques). La norme L2 permet de retarder le plus possible le sur-apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a710c3",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d8a5ae",
   "metadata": {},
   "source": [
    "Nous allons ajouter de la régularisation (Dropout) sur notre modèle, notre modèle initial n'en contient pas. Nous allons comparer avec un modèle contenant un dropout sur 3 couches cachées. Puis avec un modèle contenant sur toutes ses couches cachées un dropout pour voir l'importance de cette hyperparamètre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e35335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_dropout(num_layer: int, nodes_by_layers: List[int], full_dropout: bool) -> Model:\n",
    "    input_layer = Input(shape=(32, 32, 3))\n",
    "    hidden_layers = Flatten()(input_layer)\n",
    "    \n",
    "    for n in range(num_layer):\n",
    "        hidden_layers = Dense(nodes_by_layers[n], activation=relu, kernel_initializer=he_normal)(hidden_layers)\n",
    "        if full_dropout or n % 2 == 0:\n",
    "            hidden_layers = Dropout(0.2)(hidden_layers)\n",
    "            \n",
    "    output_layer = Dense(NUM_CLASSES, activation=softmax)(hidden_layers)\n",
    "    return Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a9b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "learning_rate = 0.01\n",
    "momentum = 0.45\n",
    "num_layers = 6\n",
    "nodes_by_layers = [32, 16, 64, 32, 16, 64]\n",
    "full_dropouts = [False, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf75d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, full_dropout in enumerate(full_dropouts):\n",
    "    mlp = MLP_dropout(num_layers, nodes_by_layers, full_dropout)\n",
    "    \n",
    "    mlp.compile(\n",
    "        loss=categorical_crossentropy,\n",
    "        optimizer=SGD(learning_rate=learning_rate, momentum=momentum),\n",
    "        metrics=categorical_accuracy\n",
    "               )\n",
    "\n",
    "    MLP_LOG = os.path.join(LOG_DIR, \"mlp\",\n",
    "                    f\"ep_{EPOCHS}_bs_{batch_size}_opt_SGD_lr_{learning_rate}_mom_{momentum}_af_relu_layers_{'_'.join(str(e) for e in nodes_by_layers)}_full_dropout_{full_dropout}_g_{i+1}\")\n",
    "\n",
    "    MLP_MODELS = os.path.join(MODELS_DIR, \"mlp\",\n",
    "                    f\"ep_{EPOCHS}_bs_{batch_size}_opt_SGD_lr_{learning_rate}_mom_{momentum}_af_relu_layers_{'_'.join(str(e) for e in nodes_by_layers)}_full_dropout_{full_dropout}_g_{i+1}.keras\")\n",
    "\n",
    "    mlp.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=EPOCHS,\n",
    "            validation_data=(x_test, y_test),\n",
    "            shuffle=SHUFFLE,\n",
    "            callbacks=[TensorBoard(MLP_LOG)]\n",
    "           )\n",
    "    mlp.save(MLP_MODELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0a46c5",
   "metadata": {},
   "source": [
    "Comparons les courbe de loss et d'accuracy de notre modèle principal avec nos deux modèles tests.\n",
    "\n",
    "**Rappel** : En bleu foncé, les courbes du modèle principal sur les données de validation. \n",
    "\n",
    "En orange, les courbes du modèle principal sur les données d'entraînement.\n",
    "\n",
    "En bleu clair, les courbes du modèle ayant un dropout sur 3 couches cachées sur les données de validation.\n",
    "\n",
    "En rouge, les courbes du modèle ayant un dropout sur 3 couches cachées sur les données d'entraînement.\n",
    "\n",
    "En vert, les courbes du modèle ayant un dropout sur toutes les couches cachées sur les données de validation.\n",
    "\n",
    "En rose, les courbes du modèle ayant un dropout sur toutes les couches cachées sur les données d'entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a2ddab",
   "metadata": {},
   "source": [
    "![Comparaison_main_dropout_test](images/MLP_g_accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382d780a",
   "metadata": {},
   "source": [
    "![Comparaison_main_dropout_test](images/MLP_g_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e5fda7",
   "metadata": {},
   "source": [
    "Commençons par comparer avec le modèle ayant un **dropout sur 3 couches cachées**, nous pouvons voir que le modèle est beaucoup plus longtemps en phase de sous-apprentissage que le modèle initiale.\n",
    "\n",
    "Pour le modèle ayant un **dropout sur toutes ses couches cachées**, nous pouvons voir que le modèle n'est même pas encore sorti de sa phase de sous-apprentissage après les 500 époques. Le Dropout comme la norme L2 sont des techniques utilisés pour empêcher des modèles de sur-apprendre, dans notre cas, c'est un peu extrême."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3473b1",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
