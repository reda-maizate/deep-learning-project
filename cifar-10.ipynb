{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c14d082c-b9bd-4d36-9039-92005273c9c8",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "La première étape intermédiaire de notre projet est d'utiliser les algorithmes ci-dessous sur le célébre dataset CIFAR-10.\n",
    "\n",
    "Les algorithmes à étudier :\n",
    "\n",
    "**Modèles précédents**\n",
    "- Modèle Linéaire\n",
    "- Perceptron Multicouches\n",
    "\n",
    "**Nouveaux modèles**\n",
    "- Conv Net(s)\n",
    "- ResNets / HighwayNets - RNN(s)\n",
    "\n",
    "Pour chacun des algorithmes cités, il faut :\n",
    "1. L'influence de tous les hyperparamètres des modèles\n",
    "    - Structure\n",
    "    - Fonctions d'activations\n",
    "    - etc.\n",
    "2. Les paramètres des algorithmes d'apprentissages\n",
    "    - Learning Rate\n",
    "    - Momentum\n",
    "    - etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dbb86e-0a9e-4648-a47e-dcd87ad1e0c5",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e378f01b-f353-4e9b-8a80-73c9b83f6bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, BatchNormalization, Input\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.activations import relu, softmax, tanh\n",
    "from tensorflow.keras.initializers import he_normal, glorot_uniform\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.random import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6c5f4e0a-0bbb-4378-a289-d8646e065ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version de TensorFlow : 2.6.0\n",
      "Nom du GPU : /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 00:14:17.708714: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-17 00:14:17.709113: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Version de TensorFlow :\", tf.__version__)\n",
    "print(\"Nom du GPU :\", tf.test.gpu_device_name())\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tf.config.optimizer.set_jit(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9a71ea-ca82-439e-8f2e-8ecef5e0e192",
   "metadata": {},
   "source": [
    "## Importation du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefc0c44-22d0-497f-affc-949cde51e72b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd58edc-df9b-49ed-ab39-9572fa1ed97a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "IMG_SIZE = x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ff4114-34f9-4e83-9ee2-a934a53403c6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 256\n",
    "x_test = x_test.astype('float32') / 256\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "y_test = to_categorical(y_test, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850b786e-e2ab-40b1-b5cc-b5cdf5125b5f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOG_DIR = os.path.join(\"logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc27c2c",
   "metadata": {},
   "source": [
    "## Fixer les seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff124095",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_seed(42) # TensorFlow\n",
    "seed(42) # NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f699da7-beb8-4e31-b040-cd63a01ab54a",
   "metadata": {},
   "source": [
    "# Modèle linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eb6a9a-24c4-4a4c-817a-e27eb4644830",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "SHUFFLE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd78c86",
   "metadata": {},
   "source": [
    "## Trouver le meilleur modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "008c642b-1c62-4643-81d6-b6a73942461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(activation_function, kernel_initializer, learning_rate, momentum, batch_size, version=''):\n",
    "    input_layer = Input(shape=(32, 32, 3))\n",
    "\n",
    "    hidden_layers = Flatten()(input_layer)\n",
    "    hidden_layers = Dense(IMG_SIZE[0] * IMG_SIZE[1] * IMG_SIZE[2], activation=activation_function, kernel_initializer=kernel_initializer)(hidden_layers)\n",
    "\n",
    "    output_layer = Dense(NUM_CLASSES, activation=softmax)(hidden_layers)\n",
    "    linear_model = Model(input_layer, output_layer)\n",
    "    \n",
    "    linear_model.compile(loss=categorical_crossentropy,\n",
    "                         optimizer=SGD(learning_rate=learning_rate,\n",
    "                                       momentum=momentum),\n",
    "                         metrics=categorical_accuracy)\n",
    "    log_name = os.path.join(LOG_DIR,\n",
    "                            \"linear\",\n",
    "                            f\"linear_model_ep_{EPOCHS}_bs_{batch_size}_opt_SGD_lr_{learning_rate}_mo_{momentum}_ki_{kernel_initializer.__name__}_af_{activation_function.__name__}{version}\")\n",
    "    history = linear_model.fit(x_train,\n",
    "                               y_train,\n",
    "                               batch_size=batch_size,\n",
    "                               epochs=EPOCHS,\n",
    "                               validation_data=(x_test, y_test),\n",
    "                               shuffle=SHUFFLE,\n",
    "                               callbacks=[TensorBoard(log_name, histogram_freq=1)])\n",
    "    return linear_model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c629f0d1",
   "metadata": {},
   "source": [
    "Les hyperparamètres que nous souhaitons ajuster :\n",
    "- learning_rates = [0.01, 0.05, 0.1, 0.2]\n",
    "- kernel_initializers = [glorot_uniform, he_normal]\n",
    "- activation_functions = [tanh, relu]\n",
    "- batch_sizes = [64, 128, 256]\n",
    "- momentums = [0, 0.5, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedfdca4-6bd4-46f8-8e3d-6f145d679371",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.05, 0.1, 0.2]\n",
    "kernel_initializers = [glorot_uniform, he_normal]\n",
    "activation_functions = [tanh, relu]\n",
    "batch_sizes = [64, 128, 256]\n",
    "momentums = [0, 0.5, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c455402-b151-4c2b-93bf-1ead051f268b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grid Search V1\n",
    "\n",
    "best_model_accuracy = 0\n",
    "counter = 0\n",
    "linear_models = {}\n",
    "\n",
    "for mo in momentums:\n",
    "    for bs in batch_sizes:\n",
    "        for af in activation_functions:\n",
    "            for ki in kernel_initializers:\n",
    "                for lr in learning_rates:\n",
    "                    print(f\"Iteration n°{counter} | af: {af.__name__} - ki: {ki.__name__} - SGD lr: {lr} / mo: {mo} - bs: {bs}\")\n",
    "                    model_name = f\"af_{af.__name__}_ki_{ki.__name__}_sgd_lr_{lr}_mo_{mo}_bs_{bs}\"\n",
    "                    model, history = linear_model(af, ki, lr, mo, bs)\n",
    "                    accuracy = round(history.history[\"categorical_accuracy\"][-1], 3)\n",
    "                    print(f\"Accuracy : {accuracy}\")\n",
    "                    linear_models[model_name] = accuracy\n",
    "                    if accuracy > best_model_accuracy:\n",
    "                        model.save(f\"models/linear/{str(accuracy)+'_'+model_name}.keras\")\n",
    "                        best_model_accuracy = accuracy\n",
    "                    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543bdfa3",
   "metadata": {},
   "source": [
    "Après une trentaine d'épochs, nous avons remarqué que nous avons les pires résultats lorsque nous utilisons un learning rate égale à 0.1 et 0.2. Du coup, nous allons les supprimer lors de la prochaine version. Nous allons aussi en profiter pour accrocher les fonctions d'activations à l'initialisateur de kernel conseillé durant le cours (tanh -> glorot_uniform et relu -> he_normal)\n",
    "\n",
    "**Résultat:**\n",
    "\n",
    "Les meilleurs modèles que nous avons ont en commun un batch size de 64, un learning rate de 0.05, peu de momentum et enfin le combo relu/he_normal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6370d279-bc7a-470f-a1e7-c35d9a9773dc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_models_sorted = sorted(linear_models.items(), key=lambda x: x[1], reverse=True)\n",
    "print(best_models_sorted[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0e1361-4dcb-4294-81f2-08b1a10cee91",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_linear_model = load_model('models/linear/af_relu_ki_HeNormal_sgd_lr_0.05_mo_0_bs_64_0.708.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88f1ef4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = best_linear_model.evaluate(x_test, y_test)\n",
    "print(f\"Test loss : {round(test_loss, 2)}\")\n",
    "print(f\"Test accuracy : {round(test_accuracy, 2) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd5cfef",
   "metadata": {},
   "source": [
    "Pour l'instant, notre meilleur modèle prédit correctement 51% du temps, ce qui est pas mal sur 10 catégories.\n",
    "Nous allons donc continuer de trouver le meilleure modèle en nous rapprochant de ces paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "723b0d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ba315e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.04, 0.05, 0.06]\n",
    "momentums = [0, 0.10, 0.25]\n",
    "batch_size = 64\n",
    "kernel_initializer = he_normal\n",
    "activation_function = relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "91f58724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 00:56:04.488204: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-12-17 00:56:04.488220: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-12-17 00:56:04.488292: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "  3/782 [..............................] - ETA: 19s - loss: 3.5146 - categorical_accuracy: 0.1042 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 00:56:05.988019: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-17 00:56:06.113635: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-12-17 00:56:06.113645: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-12-17 00:56:06.141936: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-12-17 00:56:06.142250: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-12-17 00:56:06.143566: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/linear/linear_model_ep_45_bs_64_opt_SGD_lr_0.02_mo_0.9_ki_HeNormal_af_relu_pft/train/plugins/profile/2021_12_17_00_56_06\n",
      "\n",
      "2021-12-17 00:56:06.143970: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/linear/linear_model_ep_45_bs_64_opt_SGD_lr_0.02_mo_0.9_ki_HeNormal_af_relu_pft/train/plugins/profile/2021_12_17_00_56_06/MacBook-Pro-de-Reda.local.trace.json.gz\n",
      "2021-12-17 00:56:06.144370: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/linear/linear_model_ep_45_bs_64_opt_SGD_lr_0.02_mo_0.9_ki_HeNormal_af_relu_pft/train/plugins/profile/2021_12_17_00_56_06\n",
      "\n",
      "2021-12-17 00:56:06.144579: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/linear/linear_model_ep_45_bs_64_opt_SGD_lr_0.02_mo_0.9_ki_HeNormal_af_relu_pft/train/plugins/profile/2021_12_17_00_56_06/MacBook-Pro-de-Reda.local.memory_profile.json.gz\n",
      "2021-12-17 00:56:06.145429: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/linear/linear_model_ep_45_bs_64_opt_SGD_lr_0.02_mo_0.9_ki_HeNormal_af_relu_pft/train/plugins/profile/2021_12_17_00_56_06\n",
      "Dumped tool data for xplane.pb to logs/linear/linear_model_ep_45_bs_64_opt_SGD_lr_0.02_mo_0.9_ki_HeNormal_af_relu_pft/train/plugins/profile/2021_12_17_00_56_06/MacBook-Pro-de-Reda.local.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/linear/linear_model_ep_45_bs_64_opt_SGD_lr_0.02_mo_0.9_ki_HeNormal_af_relu_pft/train/plugins/profile/2021_12_17_00_56_06/MacBook-Pro-de-Reda.local.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/linear/linear_model_ep_45_bs_64_opt_SGD_lr_0.02_mo_0.9_ki_HeNormal_af_relu_pft/train/plugins/profile/2021_12_17_00_56_06/MacBook-Pro-de-Reda.local.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/linear/linear_model_ep_45_bs_64_opt_SGD_lr_0.02_mo_0.9_ki_HeNormal_af_relu_pft/train/plugins/profile/2021_12_17_00_56_06/MacBook-Pro-de-Reda.local.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/linear/linear_model_ep_45_bs_64_opt_SGD_lr_0.02_mo_0.9_ki_HeNormal_af_relu_pft/train/plugins/profile/2021_12_17_00_56_06/MacBook-Pro-de-Reda.local.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - ETA: 0s - loss: 1.9499 - categorical_accuracy: 0.3304"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 00:56:16.150216: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 11s 14ms/step - loss: 1.9499 - categorical_accuracy: 0.3304 - val_loss: 1.8006 - val_categorical_accuracy: 0.3767\n",
      "Epoch 2/45\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 1.7747 - categorical_accuracy: 0.3830 - val_loss: 1.7528 - val_categorical_accuracy: 0.3870\n",
      "Epoch 3/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.7232 - categorical_accuracy: 0.4036 - val_loss: 1.7058 - val_categorical_accuracy: 0.4128\n",
      "Epoch 4/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.6944 - categorical_accuracy: 0.4176 - val_loss: 1.7224 - val_categorical_accuracy: 0.4053\n",
      "Epoch 5/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.6678 - categorical_accuracy: 0.4269 - val_loss: 1.7154 - val_categorical_accuracy: 0.4098\n",
      "Epoch 6/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.6451 - categorical_accuracy: 0.4365 - val_loss: 1.6457 - val_categorical_accuracy: 0.4383\n",
      "Epoch 7/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.6275 - categorical_accuracy: 0.4445 - val_loss: 1.6483 - val_categorical_accuracy: 0.4401\n",
      "Epoch 8/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.6027 - categorical_accuracy: 0.4556 - val_loss: 1.6236 - val_categorical_accuracy: 0.4465\n",
      "Epoch 9/45\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 1.6052 - categorical_accuracy: 0.4573 - val_loss: 1.6008 - val_categorical_accuracy: 0.4597\n",
      "Epoch 10/45\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 1.5871 - categorical_accuracy: 0.4645 - val_loss: 1.6136 - val_categorical_accuracy: 0.4560\n",
      "Epoch 11/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.5707 - categorical_accuracy: 0.4697 - val_loss: 1.6139 - val_categorical_accuracy: 0.4532\n",
      "Epoch 12/45\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 1.5548 - categorical_accuracy: 0.4749 - val_loss: 1.6108 - val_categorical_accuracy: 0.4493\n",
      "Epoch 13/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.5521 - categorical_accuracy: 0.4786 - val_loss: 1.5896 - val_categorical_accuracy: 0.4602\n",
      "Epoch 14/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.5330 - categorical_accuracy: 0.4868 - val_loss: 1.5839 - val_categorical_accuracy: 0.4747\n",
      "Epoch 15/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.5251 - categorical_accuracy: 0.4919 - val_loss: 1.6134 - val_categorical_accuracy: 0.4544\n",
      "Epoch 16/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.5162 - categorical_accuracy: 0.4932 - val_loss: 1.5671 - val_categorical_accuracy: 0.4804\n",
      "Epoch 17/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.5070 - categorical_accuracy: 0.5006 - val_loss: 1.6102 - val_categorical_accuracy: 0.4674\n",
      "Epoch 18/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.4985 - categorical_accuracy: 0.5011 - val_loss: 1.5990 - val_categorical_accuracy: 0.4698\n",
      "Epoch 19/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.4899 - categorical_accuracy: 0.5073 - val_loss: 1.5928 - val_categorical_accuracy: 0.4689\n",
      "Epoch 20/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.4789 - categorical_accuracy: 0.5098 - val_loss: 1.5816 - val_categorical_accuracy: 0.4661\n",
      "Epoch 21/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.4665 - categorical_accuracy: 0.5154 - val_loss: 1.5572 - val_categorical_accuracy: 0.4905\n",
      "Epoch 22/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.4530 - categorical_accuracy: 0.5216 - val_loss: 1.6043 - val_categorical_accuracy: 0.4745\n",
      "Epoch 23/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.4471 - categorical_accuracy: 0.5254 - val_loss: 1.6518 - val_categorical_accuracy: 0.4668\n",
      "Epoch 24/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.4432 - categorical_accuracy: 0.5248 - val_loss: 1.6021 - val_categorical_accuracy: 0.4741\n",
      "Epoch 25/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.4323 - categorical_accuracy: 0.5308 - val_loss: 1.5413 - val_categorical_accuracy: 0.4952\n",
      "Epoch 26/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.4327 - categorical_accuracy: 0.5335 - val_loss: 1.6126 - val_categorical_accuracy: 0.4660\n",
      "Epoch 27/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.4222 - categorical_accuracy: 0.5355 - val_loss: 1.5722 - val_categorical_accuracy: 0.4788\n",
      "Epoch 28/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.4193 - categorical_accuracy: 0.5379 - val_loss: 1.6076 - val_categorical_accuracy: 0.4698\n",
      "Epoch 29/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.4108 - categorical_accuracy: 0.5399 - val_loss: 1.5961 - val_categorical_accuracy: 0.4697\n",
      "Epoch 30/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.4060 - categorical_accuracy: 0.5419 - val_loss: 1.5739 - val_categorical_accuracy: 0.4949\n",
      "Epoch 31/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.3999 - categorical_accuracy: 0.5452 - val_loss: 1.6072 - val_categorical_accuracy: 0.4817\n",
      "Epoch 32/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.3794 - categorical_accuracy: 0.5539 - val_loss: 1.5856 - val_categorical_accuracy: 0.4786\n",
      "Epoch 33/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.3769 - categorical_accuracy: 0.5550 - val_loss: 1.5617 - val_categorical_accuracy: 0.5027\n",
      "Epoch 34/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.3707 - categorical_accuracy: 0.5612 - val_loss: 1.5624 - val_categorical_accuracy: 0.4952\n",
      "Epoch 35/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.3626 - categorical_accuracy: 0.5629 - val_loss: 1.5970 - val_categorical_accuracy: 0.4823\n",
      "Epoch 36/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.3573 - categorical_accuracy: 0.5667 - val_loss: 1.5853 - val_categorical_accuracy: 0.4945\n",
      "Epoch 37/45\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 1.3558 - categorical_accuracy: 0.5670 - val_loss: 1.5882 - val_categorical_accuracy: 0.4845\n",
      "Epoch 38/45\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 1.3412 - categorical_accuracy: 0.5732 - val_loss: 1.5959 - val_categorical_accuracy: 0.4883\n",
      "Epoch 39/45\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 1.3376 - categorical_accuracy: 0.5745 - val_loss: 1.6137 - val_categorical_accuracy: 0.4942\n",
      "Epoch 40/45\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 1.3318 - categorical_accuracy: 0.5766 - val_loss: 1.6018 - val_categorical_accuracy: 0.4843\n",
      "Epoch 41/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.3298 - categorical_accuracy: 0.5776 - val_loss: 1.5909 - val_categorical_accuracy: 0.4926\n",
      "Epoch 42/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.3251 - categorical_accuracy: 0.5813 - val_loss: 1.5649 - val_categorical_accuracy: 0.5029\n",
      "Epoch 43/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.3196 - categorical_accuracy: 0.5810 - val_loss: 1.5551 - val_categorical_accuracy: 0.5037\n",
      "Epoch 44/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.3215 - categorical_accuracy: 0.5816 - val_loss: 1.6087 - val_categorical_accuracy: 0.4887\n",
      "Epoch 45/45\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.3037 - categorical_accuracy: 0.5898 - val_loss: 1.6409 - val_categorical_accuracy: 0.4779\n",
      "Accuracy : 0.478\n"
     ]
    }
   ],
   "source": [
    "# Panda fine-tuning\n",
    "#learning_rate = 0.02\n",
    "#momentum = 0.9\n",
    "\n",
    "\n",
    "#input_layer = Input(shape=(32, 32, 3))\n",
    "\n",
    "#hidden_layers = Flatten()(input_layer)\n",
    "#hidden_layers = Dense(IMG_SIZE[0] * IMG_SIZE[1] * IMG_SIZE[2], activation=activation_function, kernel_initializer=kernel_initializer)(hidden_layers)\n",
    "\n",
    "#output_layer = Dense(NUM_CLASSES, activation=softmax,\n",
    "                     kernel_regularizer = l2(0.01),\n",
    "                     bias_regularizer = l2(0.01))(hidden_layers)\n",
    "#linear_model = Model(input_layer, output_layer)\n",
    "\n",
    "#linear_model.compile(loss=categorical_crossentropy,\n",
    "#                     optimizer=SGD(learning_rate=learning_rate,\n",
    "#                                   momentum=momentum),\n",
    "#                     metrics=categorical_accuracy)\n",
    "#log_name = os.path.join(LOG_DIR,\n",
    "#                        \"linear\",\n",
    "#                        f\"linear_model_ep_{EPOCHS}_bs_{batch_size}_opt_SGD_lr_{learning_rate}_mo_{momentum}_ki_{kernel_initializer.__name__}_af_{activation_function.__name__}_pft\")\n",
    "#history = linear_model.fit(x_train,\n",
    "#                           y_train,\n",
    "#                           batch_size=batch_size,\n",
    "#                          epochs=EPOCHS,\n",
    "#                           validation_data=(x_test, y_test),\n",
    "#                           shuffle=SHUFFLE,\n",
    "#                           callbacks=[TensorBoard(log_name, histogram_freq=1)])\n",
    "#accuracy = round(history.history[\"val_categorical_accuracy\"][-1], 3)\n",
    "#print(f\"Accuracy : {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b365705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = f\"af_{activation_function.__name__}_ki_{kernel_initializer.__name__}_sgd_lr_{0.05}_mo_{0.10}_bs_{batch_size}\"\n",
    "#linear_model.save(f\"models/linear/{str(accuracy)+'_'+model_name}.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "adbb8ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration n°1 | af: relu - ki: HeNormal - SGD lr: 0.04 / mo: 0 - bs: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 00:17:58.827727: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-12-17 00:17:58.827742: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-12-17 00:17:58.827824: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  7/782 [..............................] - ETA: 14s - loss: 5.4403 - categorical_accuracy: 0.0960"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 00:17:59.926755: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-17 00:18:00.002039: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-12-17 00:18:00.002052: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-12-17 00:18:00.029046: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-12-17 00:18:00.029373: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-12-17 00:18:00.030466: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/linear/linear_model_ep_50_bs_64_opt_SGD_lr_0.04_mo_0_ki_HeNormal_af_relu_v2/train/plugins/profile/2021_12_17_00_18_00\n",
      "\n",
      "2021-12-17 00:18:00.030903: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/linear/linear_model_ep_50_bs_64_opt_SGD_lr_0.04_mo_0_ki_HeNormal_af_relu_v2/train/plugins/profile/2021_12_17_00_18_00/MacBook-Pro-de-Reda.local.trace.json.gz\n",
      "2021-12-17 00:18:00.031317: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/linear/linear_model_ep_50_bs_64_opt_SGD_lr_0.04_mo_0_ki_HeNormal_af_relu_v2/train/plugins/profile/2021_12_17_00_18_00\n",
      "\n",
      "2021-12-17 00:18:00.031591: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/linear/linear_model_ep_50_bs_64_opt_SGD_lr_0.04_mo_0_ki_HeNormal_af_relu_v2/train/plugins/profile/2021_12_17_00_18_00/MacBook-Pro-de-Reda.local.memory_profile.json.gz\n",
      "2021-12-17 00:18:00.033799: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/linear/linear_model_ep_50_bs_64_opt_SGD_lr_0.04_mo_0_ki_HeNormal_af_relu_v2/train/plugins/profile/2021_12_17_00_18_00\n",
      "Dumped tool data for xplane.pb to logs/linear/linear_model_ep_50_bs_64_opt_SGD_lr_0.04_mo_0_ki_HeNormal_af_relu_v2/train/plugins/profile/2021_12_17_00_18_00/MacBook-Pro-de-Reda.local.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/linear/linear_model_ep_50_bs_64_opt_SGD_lr_0.04_mo_0_ki_HeNormal_af_relu_v2/train/plugins/profile/2021_12_17_00_18_00/MacBook-Pro-de-Reda.local.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/linear/linear_model_ep_50_bs_64_opt_SGD_lr_0.04_mo_0_ki_HeNormal_af_relu_v2/train/plugins/profile/2021_12_17_00_18_00/MacBook-Pro-de-Reda.local.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/linear/linear_model_ep_50_bs_64_opt_SGD_lr_0.04_mo_0_ki_HeNormal_af_relu_v2/train/plugins/profile/2021_12_17_00_18_00/MacBook-Pro-de-Reda.local.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/linear/linear_model_ep_50_bs_64_opt_SGD_lr_0.04_mo_0_ki_HeNormal_af_relu_v2/train/plugins/profile/2021_12_17_00_18_00/MacBook-Pro-de-Reda.local.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "779/782 [============================>.] - ETA: 0s - loss: 1.8277 - categorical_accuracy: 0.3605"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 00:18:09.655789: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 11s 13ms/step - loss: 1.8278 - categorical_accuracy: 0.3604 - val_loss: 1.7775 - val_categorical_accuracy: 0.3544\n",
      "Epoch 2/50\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.6237 - categorical_accuracy: 0.4254 - val_loss: 1.7577 - val_categorical_accuracy: 0.3494\n",
      "Epoch 3/50\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.5457 - categorical_accuracy: 0.4558 - val_loss: 1.6441 - val_categorical_accuracy: 0.4151\n",
      "Epoch 4/50\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 1.4899 - categorical_accuracy: 0.4770 - val_loss: 1.5948 - val_categorical_accuracy: 0.4261\n",
      "Epoch 5/50\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 1.4436 - categorical_accuracy: 0.4946 - val_loss: 1.6003 - val_categorical_accuracy: 0.4277\n",
      "Epoch 6/50\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 1.4047 - categorical_accuracy: 0.5081 - val_loss: 1.7682 - val_categorical_accuracy: 0.3889\n",
      "Epoch 7/50\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 1.3695 - categorical_accuracy: 0.5186 - val_loss: 1.6002 - val_categorical_accuracy: 0.4357\n",
      "Epoch 8/50\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.3402 - categorical_accuracy: 0.5330 - val_loss: 1.4540 - val_categorical_accuracy: 0.4827\n",
      "Epoch 9/50\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.3105 - categorical_accuracy: 0.5420 - val_loss: 1.5179 - val_categorical_accuracy: 0.4589\n",
      "Epoch 10/50\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 1.2857 - categorical_accuracy: 0.5487 - val_loss: 1.6565 - val_categorical_accuracy: 0.4459\n",
      "Epoch 11/50\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 1.2607 - categorical_accuracy: 0.5553 - val_loss: 1.4064 - val_categorical_accuracy: 0.5058\n",
      "Epoch 12/50\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.2359 - categorical_accuracy: 0.5667 - val_loss: 1.7054 - val_categorical_accuracy: 0.4111\n",
      "Epoch 13/50\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.2119 - categorical_accuracy: 0.5765 - val_loss: 1.5373 - val_categorical_accuracy: 0.4525\n",
      "Epoch 14/50\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.1868 - categorical_accuracy: 0.5833 - val_loss: 1.4950 - val_categorical_accuracy: 0.4746\n",
      "Epoch 15/50\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.1631 - categorical_accuracy: 0.5946 - val_loss: 1.5899 - val_categorical_accuracy: 0.4634\n",
      "Epoch 16/50\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.1388 - categorical_accuracy: 0.6011 - val_loss: 1.6199 - val_categorical_accuracy: 0.4548\n",
      "Epoch 17/50\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 1.1238 - categorical_accuracy: 0.6091 - val_loss: 1.9526 - val_categorical_accuracy: 0.3946\n",
      "Epoch 18/50\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.0989 - categorical_accuracy: 0.6173 - val_loss: 1.5239 - val_categorical_accuracy: 0.4721\n",
      "Epoch 19/50\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.0795 - categorical_accuracy: 0.6228 - val_loss: 2.0650 - val_categorical_accuracy: 0.3753\n",
      "Epoch 20/50\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 1.0582 - categorical_accuracy: 0.6329 - val_loss: 1.5061 - val_categorical_accuracy: 0.4760\n",
      "Epoch 21/50\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 1.0361 - categorical_accuracy: 0.6384 - val_loss: 1.7565 - val_categorical_accuracy: 0.4303\n",
      "Epoch 22/50\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 1.0169 - categorical_accuracy: 0.6454 - val_loss: 1.5421 - val_categorical_accuracy: 0.4872\n",
      "Epoch 23/50\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.9934 - categorical_accuracy: 0.6526 - val_loss: 1.8719 - val_categorical_accuracy: 0.4108\n",
      "Epoch 24/50\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.9741 - categorical_accuracy: 0.6604 - val_loss: 2.2150 - val_categorical_accuracy: 0.3726\n",
      "Epoch 25/50\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.9569 - categorical_accuracy: 0.6680 - val_loss: 1.7375 - val_categorical_accuracy: 0.4547\n",
      "Epoch 26/50\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.9424 - categorical_accuracy: 0.6719 - val_loss: 1.4540 - val_categorical_accuracy: 0.5212\n",
      "Epoch 27/50\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.9198 - categorical_accuracy: 0.6802 - val_loss: 2.5764 - val_categorical_accuracy: 0.3502\n",
      "Epoch 28/50\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.9038 - categorical_accuracy: 0.6859 - val_loss: 1.5053 - val_categorical_accuracy: 0.4963\n",
      "Epoch 29/50\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.8805 - categorical_accuracy: 0.6961 - val_loss: 1.7592 - val_categorical_accuracy: 0.4574\n",
      "Epoch 30/50\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.8594 - categorical_accuracy: 0.7024 - val_loss: 1.5692 - val_categorical_accuracy: 0.4934\n",
      "Epoch 31/50\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.8431 - categorical_accuracy: 0.7076 - val_loss: 3.3544 - val_categorical_accuracy: 0.3385\n",
      "Epoch 32/50\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.8336 - categorical_accuracy: 0.7128 - val_loss: 1.5100 - val_categorical_accuracy: 0.5142\n",
      "Epoch 33/50\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.8105 - categorical_accuracy: 0.7182 - val_loss: 1.6331 - val_categorical_accuracy: 0.4917\n",
      "Epoch 34/50\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.7954 - categorical_accuracy: 0.7242 - val_loss: 1.5160 - val_categorical_accuracy: 0.5128\n",
      "Epoch 35/50\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.7749 - categorical_accuracy: 0.7316 - val_loss: 1.5971 - val_categorical_accuracy: 0.5025\n",
      "Epoch 36/50\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.7593 - categorical_accuracy: 0.7385 - val_loss: 3.2057 - val_categorical_accuracy: 0.2707\n",
      "Epoch 37/50\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.7433 - categorical_accuracy: 0.7442 - val_loss: 2.0619 - val_categorical_accuracy: 0.4486\n",
      "Epoch 38/50\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.7246 - categorical_accuracy: 0.7518 - val_loss: 1.6981 - val_categorical_accuracy: 0.4883\n",
      "Epoch 39/50\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.7063 - categorical_accuracy: 0.7583 - val_loss: 2.8879 - val_categorical_accuracy: 0.3660\n",
      "Epoch 40/50\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.6964 - categorical_accuracy: 0.7611 - val_loss: 1.9682 - val_categorical_accuracy: 0.4569\n",
      "Epoch 41/50\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.6743 - categorical_accuracy: 0.7670 - val_loss: 1.6021 - val_categorical_accuracy: 0.5223\n",
      "Epoch 42/50\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.6522 - categorical_accuracy: 0.7795 - val_loss: 2.2155 - val_categorical_accuracy: 0.4033\n",
      "Epoch 43/50\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.6445 - categorical_accuracy: 0.7784 - val_loss: 1.7643 - val_categorical_accuracy: 0.4826\n",
      "Epoch 44/50\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.6300 - categorical_accuracy: 0.7840 - val_loss: 1.9346 - val_categorical_accuracy: 0.4638\n",
      "Epoch 45/50\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.6147 - categorical_accuracy: 0.7926 - val_loss: 2.1282 - val_categorical_accuracy: 0.4555\n",
      "Epoch 46/50\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.6031 - categorical_accuracy: 0.7964 - val_loss: 1.6970 - val_categorical_accuracy: 0.5066\n",
      "Epoch 47/50\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.5816 - categorical_accuracy: 0.8015 - val_loss: 2.4620 - val_categorical_accuracy: 0.3908\n",
      "Epoch 48/50\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.5701 - categorical_accuracy: 0.8064 - val_loss: 1.5879 - val_categorical_accuracy: 0.5279\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 10s 13ms/step - loss: 0.5557 - categorical_accuracy: 0.8123 - val_loss: 1.6474 - val_categorical_accuracy: 0.5345\n",
      "Epoch 50/50\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.5356 - categorical_accuracy: 0.8192 - val_loss: 2.5335 - val_categorical_accuracy: 0.3905\n",
      "Accuracy : 0.391\n",
      "Iteration n°2 | af: relu - ki: HeNormal - SGD lr: 0.04 / mo: 0.1 - bs: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 00:26:33.098810: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-12-17 00:26:33.098824: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-12-17 00:26:33.098878: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  8/782 [..............................] - ETA: 12s - loss: 4.8078 - categorical_accuracy: 0.0996"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 00:26:33.724586: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-17 00:26:33.810521: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-12-17 00:26:33.810529: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-12-17 00:26:33.836342: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-12-17 00:26:33.836642: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-12-17 00:26:33.837645: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/linear/linear_model_ep_50_bs_64_opt_SGD_lr_0.04_mo_0.1_ki_HeNormal_af_relu_v2/train/plugins/profile/2021_12_17_00_26_33\n",
      "\n",
      "2021-12-17 00:26:33.838088: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/linear/linear_model_ep_50_bs_64_opt_SGD_lr_0.04_mo_0.1_ki_HeNormal_af_relu_v2/train/plugins/profile/2021_12_17_00_26_33/MacBook-Pro-de-Reda.local.trace.json.gz\n",
      "2021-12-17 00:26:33.838494: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/linear/linear_model_ep_50_bs_64_opt_SGD_lr_0.04_mo_0.1_ki_HeNormal_af_relu_v2/train/plugins/profile/2021_12_17_00_26_33\n",
      "\n",
      "2021-12-17 00:26:33.838794: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/linear/linear_model_ep_50_bs_64_opt_SGD_lr_0.04_mo_0.1_ki_HeNormal_af_relu_v2/train/plugins/profile/2021_12_17_00_26_33/MacBook-Pro-de-Reda.local.memory_profile.json.gz\n",
      "2021-12-17 00:26:33.839574: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/linear/linear_model_ep_50_bs_64_opt_SGD_lr_0.04_mo_0.1_ki_HeNormal_af_relu_v2/train/plugins/profile/2021_12_17_00_26_33\n",
      "Dumped tool data for xplane.pb to logs/linear/linear_model_ep_50_bs_64_opt_SGD_lr_0.04_mo_0.1_ki_HeNormal_af_relu_v2/train/plugins/profile/2021_12_17_00_26_33/MacBook-Pro-de-Reda.local.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/linear/linear_model_ep_50_bs_64_opt_SGD_lr_0.04_mo_0.1_ki_HeNormal_af_relu_v2/train/plugins/profile/2021_12_17_00_26_33/MacBook-Pro-de-Reda.local.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/linear/linear_model_ep_50_bs_64_opt_SGD_lr_0.04_mo_0.1_ki_HeNormal_af_relu_v2/train/plugins/profile/2021_12_17_00_26_33/MacBook-Pro-de-Reda.local.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/linear/linear_model_ep_50_bs_64_opt_SGD_lr_0.04_mo_0.1_ki_HeNormal_af_relu_v2/train/plugins/profile/2021_12_17_00_26_33/MacBook-Pro-de-Reda.local.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/linear/linear_model_ep_50_bs_64_opt_SGD_lr_0.04_mo_0.1_ki_HeNormal_af_relu_v2/train/plugins/profile/2021_12_17_00_26_33/MacBook-Pro-de-Reda.local.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780/782 [============================>.] - ETA: 0s - loss: 1.8155 - categorical_accuracy: 0.3623"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 00:26:45.032421: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 12s 15ms/step - loss: 1.8155 - categorical_accuracy: 0.3623 - val_loss: 1.7611 - val_categorical_accuracy: 0.3611\n",
      "Epoch 2/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 1.6165 - categorical_accuracy: 0.4278 - val_loss: 1.7516 - val_categorical_accuracy: 0.3535\n",
      "Epoch 3/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 1.5368 - categorical_accuracy: 0.4601 - val_loss: 1.5994 - val_categorical_accuracy: 0.4249\n",
      "Epoch 4/50\n",
      "782/782 [==============================] - 11s 15ms/step - loss: 1.4816 - categorical_accuracy: 0.4804 - val_loss: 1.5883 - val_categorical_accuracy: 0.4224\n",
      "Epoch 5/50\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 1.4353 - categorical_accuracy: 0.4980 - val_loss: 1.6067 - val_categorical_accuracy: 0.4298\n",
      "Epoch 6/50\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 1.3964 - categorical_accuracy: 0.5096 - val_loss: 1.7055 - val_categorical_accuracy: 0.4037\n",
      "Epoch 7/50\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 1.3600 - categorical_accuracy: 0.5242 - val_loss: 1.5463 - val_categorical_accuracy: 0.4449\n",
      "Epoch 8/50\n",
      "707/782 [==========================>...] - ETA: 1s - loss: 1.3273 - categorical_accuracy: 0.5353"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b0/8j3ywq0d4_xdxf2sfxqf_rpr0000gn/T/ipykernel_1163/1935805951.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Iteration n°{counter} | af: {activation_function.__name__} - ki: {kernel_initializer.__name__} - SGD lr: {lr} / mo: {mo} - bs: {batch_size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"af_{af.__name__}_ki_{ki.__name__}_sgd_lr_{lr}_mo_{mo}_bs_{bs}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_v2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_categorical_accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Accuracy : {accuracy}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/b0/8j3ywq0d4_xdxf2sfxqf_rpr0000gn/T/ipykernel_1163/2076995319.py\u001b[0m in \u001b[0;36mlinear_model\u001b[0;34m(activation_function, kernel_initializer, learning_rate, momentum, batch_size, version)\u001b[0m\n\u001b[1;32m     15\u001b[0m                             \u001b[0;34m\"linear\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                             f\"linear_model_ep_{EPOCHS}_bs_{batch_size}_opt_SGD_lr_{learning_rate}_mo_{momentum}_ki_{kernel_initializer.__name__}_af_{activation_function.__name__}{version}\")\n\u001b[0;32m---> 17\u001b[0;31m     history = linear_model.fit(x_train,\n\u001b[0m\u001b[1;32m     18\u001b[0m                                \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/cours_env/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/cours_env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/cours_env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/cours_env/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/cours_env/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniforge3/envs/cours_env/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/cours_env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Grid Search V2\n",
    "\n",
    "best_model_accuracy = 0\n",
    "counter = 0\n",
    "linear_models = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for mo in momentums:\n",
    "        counter += 1\n",
    "        print(f\"Iteration n°{counter} | af: {activation_function.__name__} - ki: {kernel_initializer.__name__} - SGD lr: {lr} / mo: {mo} - bs: {batch_size}\")\n",
    "        model_name = f\"af_{activation_function.__name__}_ki_{kernel_initializer.__name__}_sgd_lr_{lr}_mo_{mo}_bs_{batch_size}\"\n",
    "        model, history = linear_model(activation_function, kernel_initializer, lr, mo, batch_size, version='_v2')\n",
    "        accuracy = round(history.history[\"val_categorical_accuracy\"][-1], 3)\n",
    "        print(f\"Accuracy : {accuracy}\")\n",
    "        linear_models[model_name] = accuracy\n",
    "        if accuracy > best_model_accuracy:\n",
    "            model.save(f\"models/linear/{str(accuracy)+'_'+model_name}.keras\")\n",
    "            best_model_accuracy = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68442913-a7c8-4c79-873a-b009912ba59b",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b553de06",
   "metadata": {},
   "source": [
    "Hyperparameter tuning using Tensorflow and Tensorboard : https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ea9914",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_LAYERS = hp.HParam('num_layers', hp.Discrete(range(2, 6)))\n",
    "NUM_UNITS = hp.HParam('num_units', hp.Discrete([8, 16, 32, 64, 128]))\n",
    "OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd', 'rmsprop']))\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 200\n",
    "SHUFFLE = True\n",
    "HPARAM_DIR = os.path.join(LOG_DIR, \"mlp\", \"hparam_tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6ee014",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.summary.create_file_writer(HPARAM_DIR).as_default():\n",
    "    hp.hparams_config(\n",
    "    hparams=[NUM_UNITS, NUM_LAYERS, OPTIMIZER],\n",
    "    metrics=[hp.Metric(\"accuracy\", display_name='Accuracy')],\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a570796-24ee-45a3-9417-3e502624b586",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mlp_model(hparams: hp) -> tf.keras.models.Model:\n",
    "    random_units = []\n",
    "    num_layer = None\n",
    "    input_ = tf.keras.layers.Input(shape=(32, 32, 3))\n",
    "    hidden_layers = tf.keras.layers.Flatten()(input_)\n",
    "    for opt in OPTIMIZER.domain.values:\n",
    "        for num_layers in NUM_LAYERS.domain.values:\n",
    "            random_unit = np.random.choice(NUM_UNITS.domain.values, 1)\n",
    "            random_units.append(random_unit)\n",
    "            hidden_layers = tf.keras.layers.Dense(random_unit, activation=\"relu\")(hidden_layers)\n",
    "\n",
    "        output_ = tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\")(hidden_layers)\n",
    "        mlp = tf.keras.models.Model(input_, output_)\n",
    "        mlp.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                    optimizer=opt,\n",
    "                    metrics=\"accuracy\")\n",
    "        MLP_LOG = os.path.join(LOG_DIR, \"mlp\", \"hparam_tuning\",\n",
    "                f\"mlp_ep_{EPOCHS}_bs_{BATCH_SIZE}_opt_{type(opt).__name__}_layers_{NUM_LAYERS}\")\n",
    "        mlp.fit(x_train,\n",
    "                y_train,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                epochs=EPOCHS,\n",
    "                validation_data=(x_test, y_test),\n",
    "                shuffle=SHUFFLE,\n",
    "                callbacks=[tf.keras.callbacks.TensorBoard(MLP_LOG, histogram_freq=1),\n",
    "                           hp.KerasCallback(MLP_LOG, hparams)]\n",
    "               )\n",
    "        _, accuracy = mlp.evaluate(x_test, y_test)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71adab3d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b081672b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
